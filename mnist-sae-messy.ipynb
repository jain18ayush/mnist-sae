{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x10c44fc70>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "partially initialized module 'torch._dynamo' has no attribute 'config' (most likely due to a circular import)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 89\u001b[0m\n\u001b[1;32m     87\u001b[0m model \u001b[38;5;241m=\u001b[39m ColoredMNISTModel()\n\u001b[1;32m     88\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m---> 89\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n",
            "File \u001b[0;32m~/Development/Interp/mnist-sae/.venv/lib/python3.11/site-packages/torch/optim/adam.py:78\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weight_decay value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_decay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     66\u001b[0m defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m     67\u001b[0m     lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m     68\u001b[0m     betas\u001b[38;5;241m=\u001b[39mbetas,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m     fused\u001b[38;5;241m=\u001b[39mfused,\n\u001b[1;32m     77\u001b[0m )\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
            "File \u001b[0;32m~/Development/Interp/mnist-sae/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py:371\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    368\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m: param_groups}]\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m param_groups:\n\u001b[0;32m--> 371\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_param_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_group\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;66;03m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;66;03m# which I don't think exists\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/72948\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warned_capturable_if_run_uncaptured \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/Development/Interp/mnist-sae/.venv/lib/python3.11/site-packages/torch/_compile.py:27\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m disable_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__dynamo_disable\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m disable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[1;32m     30\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n",
            "File \u001b[0;32m~/Development/Interp/mnist-sae/.venv/lib/python3.11/site-packages/torch/_dynamo/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_frame, eval_frame, resume_execution\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
            "File \u001b[0;32m~/Development/Interp/mnist-sae/.venv/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:53\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_python_dispatch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     48\u001b[0m     _disable_current_modes,\n\u001b[1;32m     49\u001b[0m     is_in_torch_dispatch_mode,\n\u001b[1;32m     50\u001b[0m )\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_traceback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CapturedTraceback, format_traceback_short\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config, exc, trace_rules\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_analysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m remove_dead_code, remove_pointless_jumps\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_transformation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     56\u001b[0m     check_inst_exn_tab_entries_valid,\n\u001b[1;32m     57\u001b[0m     Instruction,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m     transform_code_object,\n\u001b[1;32m     61\u001b[0m )\n",
            "File \u001b[0;32m~/Development/Interp/mnist-sae/.venv/lib/python3.11/site-packages/torch/_dynamo/trace_rules.py:3218\u001b[0m\n\u001b[1;32m   3205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdistributed\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m   3206\u001b[0m     LEGACY_MOD_INLINELIST \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3207\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.distributed.tensor._api\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.distributed.tensor.device_mesh\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.distributed._composable.replicate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3217\u001b[0m     }\n\u001b[0;32m-> 3218\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241m.\u001b[39mskip_fsdp_hooks:\n\u001b[1;32m   3219\u001b[0m         LEGACY_MOD_INLINELIST\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.distributed._composable.fsdp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3222\u001b[0m \u001b[38;5;66;03m# Force inline functions under these modules, even they are in *_SKIPLIST.\u001b[39;00m\n\u001b[1;32m   3223\u001b[0m \u001b[38;5;66;03m# We are using python module name instead of file or directory object to avoid circular dependency.\u001b[39;00m\n\u001b[1;32m   3224\u001b[0m \u001b[38;5;66;03m# Please keep this sorted alphabetically.\u001b[39;00m\n",
            "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'torch._dynamo' has no attribute 'config' (most likely due to a circular import)"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class ColoredMNISTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ColoredMNISTModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(3 * 28 * 28, 256)  # Input layer (3x28x28 pixels for RGB)\n",
        "        self.fc2 = nn.Linear(256, 128)          # Larger hidden layer\n",
        "        self.fc3 = nn.Linear(128, 10)           # Output layer (10 classes)\n",
        "\n",
        "        # Initialize a cache to store lists of activations\n",
        "        self.activation_cache = {\n",
        "            'fc1': [],\n",
        "            'fc2': [],\n",
        "            'fc3': []\n",
        "        }\n",
        "\n",
        "    def forward(self, x, cache_activations=True):\n",
        "        x = x.view(-1, 3 * 28 * 28)  # Flatten the input image (accounting for 3 channels)\n",
        "        \n",
        "        # Pass through fc1 and cache activations if needed\n",
        "        fc1_out = torch.relu(self.fc1(x))\n",
        "        if cache_activations:\n",
        "            self.activation_cache['fc1'].append(fc1_out.detach().clone())\n",
        "        \n",
        "        # Pass through fc2 and cache activations if needed\n",
        "        fc2_out = torch.relu(self.fc2(fc1_out))\n",
        "        if cache_activations:\n",
        "            self.activation_cache['fc2'].append(fc2_out.detach().clone())\n",
        "        \n",
        "        # Pass through fc3 and cache activations if needed\n",
        "        fc3_out = self.fc3(fc2_out)\n",
        "        if cache_activations:\n",
        "            self.activation_cache['fc3'].append(fc3_out.detach().clone())\n",
        "\n",
        "        return fc3_out\n",
        "\n",
        "    def get_cached_activations(self, layer_name):\n",
        "        return torch.cat(self.activation_cache[layer_name]) if layer_name in self.activation_cache else None\n",
        "\n",
        "    def clear_cache(self):\n",
        "        self.activation_cache = {\n",
        "            'fc1': [],\n",
        "            'fc2': [],\n",
        "            'fc3': []\n",
        "        }\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "epochs = 5\n",
        "\n",
        "# Transform MNIST to RGB\n",
        "class ToRGB:\n",
        "    def __call__(self, img):\n",
        "        return img.repeat(3, 1, 1)  # Repeat the grayscale channel 3 times\n",
        "\n",
        "# Updated transforms for colored MNIST\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    ToRGB(),  # Convert to RGB\n",
        "    transforms.Normalize(mean=[0.1307, 0.1307, 0.1307],  # Same normalization for each channel\n",
        "                       std=[0.3081, 0.3081, 0.3081])\n",
        "])\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Initialize model, loss function and optimizer\n",
        "model = ColoredMNISTModel()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# Optional: Test the model\n",
        "def test_model(model, test_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    print(f'Accuracy on test set: {100 * correct / total:.2f}%')\n",
        "\n",
        "test_model(model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'models/mnist_colored.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MNISTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNISTModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)  # Input layer (28x28 pixels)\n",
        "        self.fc2 = nn.Linear(128, 64)       # Hidden layer\n",
        "        self.fc3 = nn.Linear(64, 10)        # Output layer (10 classes)\n",
        "\n",
        "        # Initialize a cache to store lists of activations\n",
        "        self.activation_cache = {\n",
        "            'fc1': [],\n",
        "            'fc2': [],\n",
        "            'fc3': []\n",
        "        }\n",
        "\n",
        "    def forward(self, x, cache_activations=True):\n",
        "        x = x.view(-1, 28 * 28)  # Flatten the input image\n",
        "        \n",
        "        # Pass through fc1 and cache activations if needed\n",
        "        fc1_out = torch.relu(self.fc1(x))\n",
        "        if cache_activations:\n",
        "            self.activation_cache['fc1'].append(fc1_out.detach().clone())  # Append fc1 activations\n",
        "        \n",
        "        # Pass through fc2 and cache activations if needed\n",
        "        fc2_out = torch.relu(self.fc2(fc1_out))\n",
        "        if cache_activations:\n",
        "            self.activation_cache['fc2'].append(fc2_out.detach().clone())  # Append fc2 activations\n",
        "        \n",
        "        # Pass through fc3 and cache activations if needed\n",
        "        fc3_out = self.fc3(fc2_out)\n",
        "        if cache_activations:\n",
        "            self.activation_cache['fc3'].append(fc3_out.detach().clone())  # Append fc3 activations\n",
        "\n",
        "        return fc3_out\n",
        "\n",
        "    # Method to retrieve cached activations for a specified layer\n",
        "    def get_cached_activations(self, layer_name):\n",
        "        return torch.cat(self.activation_cache[layer_name]) if layer_name in self.activation_cache else None\n",
        "\n",
        "    # Method to clear the cache\n",
        "    def clear_cache(self):\n",
        "        self.activation_cache = {\n",
        "            'fc1': [],\n",
        "            'fc2': [],\n",
        "            'fc3': []\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IkB3CSGham1e",
        "outputId": "eeb79734-1272-4180-e8f2-a56ec1ccb09a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Hyperparameters\n",
        "\n",
        "learning_rate = 0.001\n",
        "epochs = 5\n",
        "\n",
        "# MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))  # Mean and std deviation of MNIST dataset\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "MNIST_test_dataset = test_dataset #* Test dataset for mnist class \n",
        "print(batch_size)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Initialize model, loss function and optimizer\n",
        "model = MNISTModel()\n",
        "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "all_activations = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()  # Zero out previous gradients\n",
        "        outputs = model(images)  # Get output and activations from fc2\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Gradient descent\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Store activations for the sparse autoencoder\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'models/mnist_model.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#* Test Accuracy Loop \n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"Test accuracy: {100 * correct / total}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cache Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "#* Test Accuracy Loop \n",
        "model.clear_cache()\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images, cache_activations=True)\n",
        "        _, predicted = torch.max(outputs.data, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([10000, 256]), torch.Size([10000, 128]), torch.Size([10000, 10]))"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.get_cached_activations('fc1').shape, model.get_cached_activations('fc2').shape, model.get_cached_activations('fc3').shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10000, 28, 28])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_loader.dataset.data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Maximally Activating Image Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "class AnalysisMNISTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AnalysisMNISTModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        fc1_out = torch.relu(self.fc1(x))\n",
        "        fc2_out = torch.relu(self.fc2(fc1_out))\n",
        "        fc3_out = self.fc3(fc2_out)\n",
        "        return fc3_out, fc1_out, fc2_out\n",
        "\n",
        "def gaussian_blur(img, kernel_size=3, sigma=1.0):\n",
        "    # Ensure the image has a batch dimension\n",
        "    if img.dim() == 3:\n",
        "        img = img.unsqueeze(0)\n",
        "    \n",
        "    # Create the Gaussian kernel\n",
        "    kernel = torch.tensor([\n",
        "        [1, 2, 1],\n",
        "        [2, 4, 2],\n",
        "        [1, 2, 1]\n",
        "    ], dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
        "    kernel = kernel / kernel.sum()\n",
        "    \n",
        "    # Apply the convolution\n",
        "    padding = (kernel_size - 1) // 2\n",
        "    blurred = F.conv2d(img, kernel, padding=padding, groups=img.shape[1])\n",
        "    \n",
        "    return blurred.squeeze(0)  # Remove the batch dimension\n",
        "\n",
        "def activation_maximization(model, layer_index, neuron_index, num_iterations=500, learning_rate=0.1):\n",
        "    model.eval()\n",
        "    \n",
        "    # Create a random input image\n",
        "    input_image = torch.randn(1, 1, 28, 28, requires_grad=True)\n",
        "    \n",
        "    # Define the optimizer\n",
        "    optimizer = torch.optim.Adam([input_image], lr=learning_rate)\n",
        "    \n",
        "    # Define transforms for regularization\n",
        "    jitter = transforms.Compose([\n",
        "        transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=15),\n",
        "    ])\n",
        "    \n",
        "    for i in range(num_iterations):\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Apply jitter transformation\n",
        "        jittered_image = jitter(input_image)\n",
        "        \n",
        "        # Apply custom Gaussian blur\n",
        "        blurred_image = gaussian_blur(jittered_image, kernel_size=3, sigma=0.5)\n",
        "        \n",
        "        # Forward pass\n",
        "        _, fc1_out, fc2_out = model(blurred_image)\n",
        "        \n",
        "        # Get the activation of the specified neuron\n",
        "        if layer_index == 0:\n",
        "            target_activation = fc1_out[0, neuron_index]\n",
        "        elif layer_index == 1:\n",
        "            target_activation = fc2_out[0, neuron_index]\n",
        "        else:\n",
        "            raise ValueError(\"Invalid layer index\")\n",
        "        \n",
        "        # Compute the loss (negative activation to maximize it)\n",
        "        loss = -target_activation\n",
        "        \n",
        "        # Add L2 regularization\n",
        "        l2_reg = 1e-3 * torch.sum(input_image**2)\n",
        "        loss += l2_reg\n",
        "        \n",
        "        # Add total variation regularization\n",
        "        tv_reg = 1e-4 * (torch.sum(torch.abs(input_image[:,:,:-1] - input_image[:,:,1:])) + \n",
        "                         torch.sum(torch.abs(input_image[:,:-1,:] - input_image[:,1:,:])))\n",
        "        loss += tv_reg\n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update the input image\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Clip the image values to be between 0 and 1\n",
        "        with torch.no_grad():\n",
        "            input_image.clamp_(0, 1)\n",
        "        \n",
        "        # Periodically apply sharpening\n",
        "        if i % 50 == 0:\n",
        "            input_image.data = sharpen(input_image.data)\n",
        "    \n",
        "    # Normalize the resulting image\n",
        "    optimized_image = input_image.squeeze().detach()\n",
        "    optimized_image = (optimized_image - optimized_image.min()) / (optimized_image.max() - optimized_image.min())\n",
        "    \n",
        "    return optimized_image\n",
        "\n",
        "def sharpen(image):\n",
        "    \"\"\"Apply a sharpening filter to the image.\"\"\"\n",
        "    blurred = gaussian_blur(image, kernel_size=3, sigma=1.0)\n",
        "    sharpened = image + (image - blurred) * 0.5\n",
        "    return torch.clamp(sharpened, 0, 1)\n",
        "\n",
        "def visualize_neuron_activations(model, layer_index, num_neurons=64):\n",
        "    rows = int((num_neurons)**0.5)\n",
        "    cols = (num_neurons + rows - 1) // rows\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(cols*3, rows*3))\n",
        "    axes = axes.ravel()\n",
        "    \n",
        "    for i in range(num_neurons):\n",
        "        optimized_image = activation_maximization(model, layer_index, i)\n",
        "        axes[i].imshow(optimized_image, cmap='gray')\n",
        "        axes[i].set_title(f'Neuron {i}')\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    # Hide any unused subplots\n",
        "    for j in range(num_neurons, len(axes)):\n",
        "        axes[j].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'docs/images/MNIST-activation_maximization-layer{layer_index}.png')\n",
        "    plt.show()\n",
        "\n",
        "# Assuming you have already trained your model\n",
        "model = AnalysisMNISTModel()\n",
        "# Load your trained weights here if necessary\n",
        "model.load_state_dict(torch.load('models/mnist_model.pth'))\n",
        "\n",
        "# Example usage\n",
        "visualize_neuron_activations(model, layer_index=0, num_neurons=64)  # Visualize fc2 layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Maps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_feature_maps(model, data_loader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    for images, _ in data_loader:\n",
        "        with torch.no_grad():\n",
        "            _, fc1_out, fc2_out = model(images)\n",
        "            \n",
        "            # Visualize activations of the first image in the batch\n",
        "            plt.figure(figsize=(12, 5))\n",
        "            plt.subplot(1, 2, 1)\n",
        "            plt.bar(range(fc1_out.shape[1]), fc1_out[0].numpy())\n",
        "            plt.title('fc1 Feature Map')\n",
        "            \n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.bar(range(fc2_out.shape[1]), fc2_out[0].numpy())\n",
        "            plt.title('fc2 Feature Map')\n",
        "            plt.show()\n",
        "        \n",
        "        break  # Just show for the first batch\n",
        "\n",
        "# Example usage:\n",
        "visualize_feature_maps(model, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL6Kne88HFOj"
      },
      "source": [
        "## SAE\n",
        "\n",
        "*Activations Shapes:* \n",
        "- fc1: torch.Size([10000, 128])\n",
        "- fc2: torch.Size([10000, 64])\n",
        "- fc3: torch.Size([10000, 10]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LayerConfig:\n",
        "    def __init__(self, name, input_dim):\n",
        "        self.name = name\n",
        "        self.input_dim = input_dim\n",
        "\n",
        "# Create instances for each layer\n",
        "fc1_config = LayerConfig('fc1', 256)\n",
        "fc2_config = LayerConfig('fc2', 64)\n",
        "fc3_config = LayerConfig('fc3', 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Simple SAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrVJaAeOhmi6",
        "outputId": "94f61f99-4fbe-480c-b659-2264b4f70426"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class SimpleSAE(nn.Module):\n",
        "    def __init__(self, input_dim=64, hidden_dim=32, l1_coeff=0.1, seed=42):\n",
        "        super(SimpleSAE, self).__init__()\n",
        "        torch.manual_seed(seed)\n",
        "        self.encoder = nn.Linear(input_dim, hidden_dim)\n",
        "        self.decoder = nn.Linear(hidden_dim, input_dim)\n",
        "        self.l1_coeff = l1_coeff  # L1 regularization coefficient for sparsity\n",
        "        \n",
        "        # Initialize a cache to store lists of activations\n",
        "        self.activation_cache = {\n",
        "            'encoder': [],\n",
        "            'decoder': []\n",
        "        }\n",
        "\n",
        "    def forward(self, x, cache_activations=False):\n",
        "        # Encoder: Reduce the dimensionality\n",
        "        encoded = torch.relu(self.encoder(x))\n",
        "        if cache_activations:\n",
        "            self.activation_cache['encoder'].append(encoded.detach().clone())  # Append encoder activations\n",
        "\n",
        "        # Decoder: Reconstruct the original input\n",
        "        decoded = self.decoder(encoded)\n",
        "        if cache_activations:\n",
        "            self.activation_cache['decoder'].append(decoded.detach().clone())  # Append decoder activations\n",
        "\n",
        "        return encoded, decoded\n",
        "\n",
        "    def compute_loss(self, x, decoded, encoded):\n",
        "        # Reconstruction Loss (MSE)\n",
        "        recon_loss = nn.MSELoss()(decoded, x)\n",
        "\n",
        "        # L1 Sparsity Loss (L1 regularization on encoded activations)\n",
        "        l1_loss = self.l1_coeff * torch.sum(torch.abs(encoded))\n",
        "\n",
        "        # Combine losses: L = MSE + λ * L1\n",
        "        loss = recon_loss + l1_loss\n",
        "\n",
        "        return loss\n",
        "\n",
        "    # Method to retrieve cached activations for a specified layer\n",
        "    def get_cached_activations(self, layer_name):\n",
        "        return torch.cat(self.activation_cache[layer_name]) if layer_name in self.activation_cache else None\n",
        "\n",
        "    # Method to clear the cache\n",
        "    def clear_cache(self):\n",
        "        self.activation_cache = {\n",
        "            'encoder': [],\n",
        "            'decoder': []\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math \n",
        "import torch.nn.functional as F\n",
        "\n",
        "class EnhancedSAE(nn.Module):\n",
        "    def __init__(self, input_dim=64, hidden_dim=32, l1_coeff=0.1, seed=42):\n",
        "        super(EnhancedSAE, self).__init__()\n",
        "        self.l1_coeff = l1_coeff  # L1 regularization coefficient for sparsity\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "        # Encoder and decoder with Kaiming initialization\n",
        "        self.encoder = nn.Linear(input_dim, hidden_dim)\n",
        "        self.decoder = nn.Linear(hidden_dim, input_dim)\n",
        "\n",
        "        nn.init.kaiming_uniform_(self.encoder.weight, a=math.sqrt(5))\n",
        "        nn.init.kaiming_uniform_(self.decoder.weight, a=math.sqrt(5))\n",
        "        self.encoder.bias.data.zero_()\n",
        "        self.decoder.bias.data.zero_()\n",
        "\n",
        "        self.activation_cache = {\n",
        "            'encoder': [],\n",
        "            'decoder': []\n",
        "        }\n",
        "\n",
        "\n",
        "    def forward(self, x, cache_activations=True):\n",
        "        # Center the input\n",
        "        x_centered = x - self.decoder.bias\n",
        "        # Encoder: Reduce the dimensionality\n",
        "        encoded = F.relu(self.encoder(x_centered))\n",
        "        \n",
        "        if cache_activations:\n",
        "            self.activation_cache['encoder'].append(encoded.detach().clone())  # Append encoder activations\n",
        "\n",
        "        # Decoder: Reconstruct the original input\n",
        "        decoded = self.decoder(encoded)\n",
        "        if cache_activations:\n",
        "            self.activation_cache['decoder'].append(decoded.detach().clone())  # Append decoder activations\n",
        "\n",
        "        return encoded, decoded\n",
        "\n",
        "    def compute_loss(self, x, decoded, encoded):\n",
        "        # Reconstruction Loss (MSE)\n",
        "        recon_loss = nn.MSELoss()(decoded, x)\n",
        "\n",
        "        # L1 Sparsity Loss (L1 regularization on encoded activations)\n",
        "        l1_loss = self.l1_coeff * torch.sum(torch.abs(encoded))\n",
        "\n",
        "        # Combine losses: L = MSE + λ * L1\n",
        "        loss = recon_loss + l1_loss\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def get_cached_activations(self, layer_name):\n",
        "        return torch.cat(self.activation_cache[layer_name]) if layer_name in self.activation_cache else None\n",
        "\n",
        "\n",
        "    def clear_cache(self):\n",
        "        self.activation_cache = {\n",
        "            'encoder': [],\n",
        "            'decoder': []\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Choose the layer configuration you want to use\n",
        "selected_layer_config = fc1_config  # Change this to fc2_config or fc3_config as needed\n",
        "\n",
        "# Use the selected layer configuration\n",
        "input_dim = selected_layer_config.input_dim\n",
        "hidden_dim = 2304\n",
        "sae = EnhancedSAE(input_dim=input_dim, hidden_dim=hidden_dim, l1_coeff=0.01)\n",
        "\n",
        "# Optimizer\n",
        "optimizer_sae = optim.Adam(sae.parameters(), lr=learning_rate)\n",
        "\n",
        "# Activations loaded from cache\n",
        "train_activations = model.get_cached_activations(selected_layer_config.name)\n",
        "\n",
        "# Split the activations into train and test sets (80% train, 20% test)\n",
        "train_activations, test_activations = train_test_split(train_activations, test_size=0.2, random_state=42)\n",
        "\n",
        "# DataLoader for activations\n",
        "train_activations_loader = DataLoader(train_activations, batch_size=batch_size, shuffle=True)\n",
        "test_activations_loader = DataLoader(test_activations, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "SAE_test_activations = test_activations #* Test dataset for SAE class\n",
        "\n",
        "# Training Loop for SAE\n",
        "epochs = 50  # You can adjust this based on your preference\n",
        "for epoch in range(epochs):\n",
        "    sae.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_activations_loader:\n",
        "        optimizer_sae.zero_grad()  # Zero out previous gradients\n",
        "\n",
        "        # Forward pass through the SAE\n",
        "        encoded, decoded = sae(batch)\n",
        "\n",
        "        # Compute loss (MSE + sparsity penalty)\n",
        "        loss = sae.compute_loss(batch, decoded, encoded)\n",
        "\n",
        "        loss.backward()  # Backprop for SAE\n",
        "        optimizer_sae.step()  # Optimizer step\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"SAE Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_activations_loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Activations loaded from cache\n",
        "train_activations = model.get_cached_activations(selected_layer_config.name)\n",
        "\n",
        "# Split the activations into train and test sets (80% train, 20% test)\n",
        "train_activations, test_activations = train_test_split(train_activations, test_size=0.2, random_state=42)\n",
        "\n",
        "# DataLoader for activations\n",
        "train_activations_loader = DataLoader(train_activations, batch_size=batch_size, shuffle=True)\n",
        "test_activations_loader = DataLoader(test_activations, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/bl/kzfk5ts90gj98y9jcv49ynmc0000gn/T/ipykernel_73347/1586278045.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  sae.load_state_dict(torch.load('models/mnist_sae_colored.pth'))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SAE Test Loss: 15.6865\n"
          ]
        }
      ],
      "source": [
        "# Evaluation Loop for SAE\n",
        "sae.load_state_dict(torch.load('models/mnist_sae_colored.pth'))\n",
        "sae.eval()\n",
        "total_test_loss = 0\n",
        "with torch.no_grad():\n",
        "    for batch in test_activations_loader:\n",
        "        # Forward pass through the SAE\n",
        "        encoded, decoded = sae(batch)\n",
        "\n",
        "        # Compute loss (MSE + sparsity penalty)\n",
        "        loss = sae.compute_loss(batch, decoded, encoded)\n",
        "\n",
        "        total_test_loss += loss.item()\n",
        "\n",
        "print(f\"SAE Test Loss: {total_test_loss/len(test_activations_loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(sae.state_dict(), 'models/mnist_sae_colored.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Activation Maximization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def plot_reconstructions(model, test_data, num_samples=10):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        samples = test_data[:num_samples]\n",
        "        _, reconstructions = model(samples)\n",
        "    \n",
        "    fig, axes = plt.subplots(2, num_samples, figsize=(20, 4))\n",
        "    for i in range(num_samples):\n",
        "        axes[0, i].imshow(samples[i].reshape(8,16), cmap='gray')\n",
        "        axes[0, i].axis('off')\n",
        "        axes[0, i].set_title('Original')\n",
        "        \n",
        "        axes[1, i].imshow(reconstructions[i].reshape(8,16), cmap='gray')\n",
        "        axes[1, i].axis('off')\n",
        "        axes[1, i].set_title('Reconstructed')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_latent_space(model, test_data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        encoded, _ = model(test_data)\n",
        "    \n",
        "    encoded = encoded.numpy()\n",
        "    pca = PCA(n_components=2)\n",
        "    encoded_2d = pca.fit_transform(encoded)\n",
        "    \n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.scatter(encoded_2d[:, 0], encoded_2d[:, 1], alpha=0.5)\n",
        "    plt.title('2D PCA of Latent Space')\n",
        "    plt.xlabel('First Principal Component')\n",
        "    plt.ylabel('Second Principal Component')\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "def plot_feature_activations(model, test_data, num_features=10):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        encoded, _ = model(test_data)\n",
        "    \n",
        "    feature_activations = encoded.mean(dim=0)\n",
        "    top_features = torch.argsort(feature_activations, descending=True)[:num_features]\n",
        "    \n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.bar(range(num_features), feature_activations[top_features])\n",
        "    plt.title(f'Top {num_features} Most Active Features')\n",
        "    plt.xlabel('Feature Index')\n",
        "    plt.ylabel('Average Activation')\n",
        "    plt.show()\n",
        "\n",
        "def compute_cosine_similarity(model, test_data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        encoded, _ = model(test_data)\n",
        "    \n",
        "    encoded = encoded.numpy()\n",
        "    similarity_matrix = cosine_similarity(encoded)\n",
        "    \n",
        "    nonzero_indices = np.nonzero(similarity_matrix)\n",
        "    nonzero_values = similarity_matrix[nonzero_indices]\n",
        "    \n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.scatter(nonzero_indices[0], nonzero_indices[1], c=nonzero_values, cmap='viridis')\n",
        "    plt.colorbar()\n",
        "    plt.title('Nonzero Cosine Similarity of Encoded Representations')\n",
        "    plt.xlabel('Sample Index')\n",
        "    plt.ylabel('Sample Index')\n",
        "    plt.show()\n",
        "\n",
        "def activation_maximization_sae(model, neuron_index, num_iterations=100, learning_rate=0.1):\n",
        "    model.eval()\n",
        "    \n",
        "    # Create a random input\n",
        "    input_data = torch.randn(1, model.encoder.in_features, requires_grad=True)\n",
        "    \n",
        "    optimizer = torch.optim.Adam([input_data], lr=learning_rate)\n",
        "    \n",
        "    for _ in range(num_iterations):\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass\n",
        "        encoded, _ = model(input_data)\n",
        "        \n",
        "        # Get the activation of the specified neuron\n",
        "        target_activation = encoded[0, neuron_index]\n",
        "        \n",
        "        # Compute the loss (negative activation to maximize it)\n",
        "        loss = -target_activation\n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update the input\n",
        "        optimizer.step()\n",
        "    \n",
        "    # Normalize the resulting input\n",
        "    optimized_input = input_data.squeeze().detach()\n",
        "    optimized_input = (optimized_input - optimized_input.min()) / (optimized_input.max() - optimized_input.min())\n",
        "    \n",
        "    return optimized_input\n",
        "\n",
        "def visualize_neuron_activations_sae(model, num_neurons=10):\n",
        "    rows = (num_neurons + 4) // 5  # Calculate the number of rows needed\n",
        "    fig, axes = plt.subplots(rows, 5, figsize=(15, 3 * rows))\n",
        "    axes = axes.ravel()\n",
        "    \n",
        "    for i in range(num_neurons):\n",
        "        optimized_input = activation_maximization_sae(model, i)\n",
        "        axes[i].imshow(optimized_input.reshape(8, 16), cmap='gray')\n",
        "        axes[i].set_title(f'Neuron {i}')\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    # Hide any unused subplots\n",
        "    for j in range(num_neurons, len(axes)):\n",
        "        axes[j].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "plot_reconstructions(sae, SAE_test_activations)\n",
        "plot_latent_space(sae, SAE_test_activations)\n",
        "plot_feature_activations(sae, SAE_test_activations)\n",
        "compute_cosine_similarity(sae, SAE_test_activations)\n",
        "visualize_neuron_activations_sae(sae, num_neurons=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What have I done so far? \n",
        "\n",
        "- Created MNIST: ~97% accuracy \n",
        "- Trained two SAEs on MNIST\n",
        "    - SimpleSAE (just encoder decoder)\n",
        "    - ComplexSae (Based off of Neel Nanda's sae when replicating monosemanticity paper) \n",
        "- Simple seems to performs slightly better \n",
        "\n",
        "*Set to a random seed* \n",
        " \n",
        "Next Steps: \n",
        "- Cache all activations when testing the sae\n",
        "- Take the middle layer of the encoder of sae and pass it back into simple sae \n",
        "\n",
        "Confusions: \n",
        "- Should the hidden layer of an SAE be larger than the input\n",
        "    - *What is a hidden layer?* \n",
        "\n",
        "### NEED TO TRACK MAX ACTIVATIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Meta-SAE Time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoder_config = LayerConfig('encoder', 2304)\n",
        "decoder_config = LayerConfig('decoder', 128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cache activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation Loop for SAE\n",
        "sae.clear_cache()\n",
        "sae.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in test_activations_loader:\n",
        "        # Forward pass through the SAE\n",
        "        encoded, decoded = sae(batch, cache_activations=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "62000"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(test_activations_loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([62000, 2304]), torch.Size([62000, 256]))"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get cached activations\n",
        "sae.get_cached_activations('encoder').shape, sae.get_cached_activations('decoder').shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "selected_layer_config = encoder_config\n",
        "input_dim = selected_layer_config.input_dim\n",
        "hidden_dim = 49152\n",
        "meta_sae = EnhancedSAE(input_dim=input_dim, hidden_dim=hidden_dim, l1_coeff=0.01)\n",
        "\n",
        "optimizer_sae = optim.Adam(meta_sae.parameters(), lr=learning_rate)\n",
        "\n",
        "train_activations = sae.get_cached_activations(selected_layer_config.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "train_activations, test_activations = train_test_split(train_activations, test_size=0.2, random_state=42)\n",
        "\n",
        "META_SAE_test_activations = test_activations #* Test dataset for META_SAE class\n",
        "\n",
        "train_activations_loader = DataLoader(train_activations, batch_size=batch_size, shuffle=True)\n",
        "test_activations_loader = DataLoader(test_activations, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    meta_sae.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_activations_loader:\n",
        "        optimizer_sae.zero_grad()\n",
        "        encoded, decoded = meta_sae(batch)\n",
        "\n",
        "        loss = meta_sae.compute_loss(batch, decoded, encoded)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer_sae.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"SAE Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_activations_loader):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "meta_sae.eval()\n",
        "total_test_loss = 0\n",
        "with torch.no_grad():\n",
        "    for batch in test_activations_loader:\n",
        "        # Forward pass through the SAE\n",
        "        encoded, decoded = meta_sae(batch)\n",
        "\n",
        "        # Compute loss (MSE + sparsity penalty)\n",
        "        loss = meta_sae.compute_loss(batch, decoded, encoded)\n",
        "\n",
        "        total_test_loss += loss.item()\n",
        "\n",
        "print(f\"SAE Test Loss: {total_test_loss/len(test_activations_loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Activation maximization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm import tqdm\n",
        "\n",
        "def plot_reconstructions(model, test_data, num_samples=10):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        samples = test_data[:num_samples]\n",
        "        _, reconstructions = model(samples)\n",
        "    \n",
        "    fig, axes = plt.subplots(2, num_samples, figsize=(20, 4))\n",
        "    for i in range(num_samples):\n",
        "        axes[0, i].imshow(samples[i].reshape(48,48), cmap='gray')\n",
        "        axes[0, i].axis('off')\n",
        "        axes[0, i].set_title('Original')\n",
        "        \n",
        "        axes[1, i].imshow(reconstructions[i].reshape(48,48), cmap='gray')\n",
        "        axes[1, i].axis('off')\n",
        "        axes[1, i].set_title('Reconstructed')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def plot_latent_space(model, test_data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        encoded, _ = model(test_data)\n",
        "    \n",
        "    encoded = encoded.numpy()\n",
        "    pca = PCA(n_components=2)\n",
        "    encoded_2d = pca.fit_transform(encoded)\n",
        "    \n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.scatter(encoded_2d[:, 0], encoded_2d[:, 1], alpha=0.5)\n",
        "    plt.title('2D PCA of Latent Space')\n",
        "    plt.xlabel('First Principal Component')\n",
        "    plt.ylabel('Second Principal Component')\n",
        "    plt.colorbar()\n",
        "    plt.show()\n",
        "\n",
        "def plot_feature_activations(model, test_data, num_features=10):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        encoded, _ = model(test_data)\n",
        "    \n",
        "    feature_activations = encoded.mean(dim=0)\n",
        "    top_features = torch.argsort(feature_activations, descending=True)[:num_features]\n",
        "    \n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.bar(range(num_features), feature_activations[top_features])\n",
        "    plt.title(f'Top {num_features} Most Active Features')\n",
        "    plt.xlabel('Feature Index')\n",
        "    plt.ylabel('Average Activation')\n",
        "    plt.show()\n",
        "\n",
        "def compute_cosine_similarity(model, test_data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        encoded, _ = model(test_data)\n",
        "    \n",
        "    encoded = encoded.numpy()\n",
        "    similarity_matrix = cosine_similarity(encoded)\n",
        "    \n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(similarity_matrix, cmap='viridis')\n",
        "    plt.colorbar()\n",
        "    plt.title('Cosine Similarity of Encoded Representations')\n",
        "    plt.xlabel('Sample Index')\n",
        "    plt.ylabel('Sample Index')\n",
        "    plt.show()\n",
        "\n",
        "def activation_maximization_sae(model, neuron_index, num_iterations=100, learning_rate=0.1):\n",
        "    model.eval()\n",
        "    \n",
        "    # Create a random input\n",
        "    input_data = torch.randn(1, model.encoder.in_features, requires_grad=True)\n",
        "    \n",
        "    optimizer = torch.optim.Adam([input_data], lr=learning_rate)\n",
        "    \n",
        "    for _ in range(num_iterations):\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward pass\n",
        "        encoded, _ = model(input_data)\n",
        "        \n",
        "        # Get the activation of the specified neuron\n",
        "        target_activation = encoded[0, neuron_index]\n",
        "        \n",
        "        # Compute the loss (negative activation to maximize it)\n",
        "        loss = -target_activation\n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update the input\n",
        "        optimizer.step()\n",
        "    \n",
        "    # Normalize the resulting input\n",
        "    optimized_input = input_data.squeeze().detach()\n",
        "    optimized_input = (optimized_input - optimized_input.min()) / (optimized_input.max() - optimized_input.min())\n",
        "    \n",
        "    return optimized_input\n",
        "\n",
        "def visualize_neuron_activations_sae(model, num_neurons=10):\n",
        "    rows = (num_neurons + 4) // 5  # Calculate the number of rows needed\n",
        "    fig, axes = plt.subplots(rows, 5, figsize=(15, 3 * rows))\n",
        "    axes = axes.ravel()\n",
        "    \n",
        "    for i in tqdm(range(num_neurons)):\n",
        "        optimized_input = activation_maximization_sae(model, i)\n",
        "        axes[i].imshow(optimized_input.reshape(48,48), cmap='gray')\n",
        "        axes[i].set_title(f'Neuron {i}')\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    # Hide any unused subplots\n",
        "    for j in range(num_neurons, len(axes)):\n",
        "        axes[j].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "plot_reconstructions(meta_sae, META_SAE_test_activations)\n",
        "plot_latent_space(meta_sae, META_SAE_test_activations)\n",
        "plot_feature_activations(meta_sae, META_SAE_test_activations)\n",
        "compute_cosine_similarity(meta_sae, META_SAE_test_activations)\n",
        "visualize_neuron_activations_sae(meta_sae, num_neurons=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Notes\n",
        "\n",
        "- meta sae has reallly good loss???\n",
        "- Whats topk and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation\n",
        "\n",
        "How does ViT Prisma do thier emjoi thing? --> Want to track the change in the models understanding of the number over time. \n",
        "wth is a logit --> \n",
        "\n",
        "- Max Activation Evalution\n",
        "\n",
        "1.  MNIST: Run the train set and cache activations \n",
        "        *Store the output labels*\n",
        "2.  Take the labels from the MNIST test and run those activations through the SAE and track max activations of the encoder output layer. \n",
        "3.  Take the acrtivations of the encoder output and track max activations of the encoder output layer \n",
        "\n",
        "(2) (3) can have a function in the simple sae class to help with tracking max activations of the SAE \n",
        "\n",
        "\n",
        "- model -> MNIST \n",
        "- sae -> MNIST Sae \n",
        "- meta-sae -> Sae on MNIST Sae\n",
        "\n",
        "\n",
        "Need to rename all the data loaders to be by class\n",
        "\n",
        "### What data do I have + want?\n",
        "- labels from MNIST\n",
        "- activations of the encoder for each sae\n",
        "- activations of fc1, 2, 3 for mnist \n",
        "\n",
        "- for each activation what is the max neuron and its value --> what was the expected number "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MNIST Max Activations\n",
        "\n",
        "1. Save the top neuron that activated and its value. \n",
        "2. Run the test set through and save the labels. \n",
        "3. After the run and having the cache iterate through the cache and labels \n",
        "4. Add to a df the argmax ( neuron) and max value \n",
        "5. add the projected label as well \n",
        "\n",
        "*Critical Oversight: The model will change its prediction over time and I am not tracking that* "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MNIST_test_dataset #*dataset run through MNIST \n",
        "print(SAE_test_activations) #* MNIST activations run through sae\n",
        "print(META_SAE_test_activations) #* Sae activations run through meta-sae    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Initialize a dictionary to store results\n",
        "results_dict = {\"Max_Value\": [], \"Neuron_Index\": [], \"Predicted_Label\": []}\n",
        "\n",
        "# Set batch size and initialize DataLoader\n",
        "batch_size = 646+\n",
        "test_loader = DataLoader(dataset=MNIST_test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Clear cache at the start and set model to evaluation mode\n",
        "model.clear_cache()\n",
        "model.eval()\n",
        "\n",
        "# Iterate over test data\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        # Get outputs and cache activations for this batch\n",
        "        outputs = model(images, cache_activations=True)\n",
        "        \n",
        "        # Predicted labels for the batch\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        \n",
        "        # Process activations from fc1 for the batch\n",
        "        fc1_activations = model.get_cached_activations('fc1')\n",
        "        \n",
        "        # Iterate through the batch to find max activation for each image\n",
        "        for i in range(fc1_activations.size(0)):  # Iterate through batch size\n",
        "            activations = fc1_activations[i]\n",
        "            \n",
        "            # Find the max activation value and corresponding neuron index\n",
        "            max_value, neuron_index = torch.max(activations, 0)\n",
        "            \n",
        "            # Append results to dictionary\n",
        "            results_dict[\"Max_Value\"].append(max_value.item())\n",
        "            results_dict[\"Neuron_Index\"].append(neuron_index.item())\n",
        "            results_dict[\"Predicted_Label\"].append(predicted[i].item())\n",
        "        \n",
        "        # Clear cache manually after processing this batch\n",
        "        model.clear_cache()\n",
        "\n",
        "# Convert the dictionary to a DataFrame\n",
        "MNIST_results_df = pd.DataFrame(results_dict)\n",
        "\n",
        "# After the loop, the DataFrame will contain max activations and neuron indices\n",
        "MNIST_results_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "MNIST_results_df.to_csv('docs/MNIST_results.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SAE Max Activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Initialize a dictionary to store results\n",
        "results_dict = {\"Max_Value\": [], \"Neuron_Index\": []}\n",
        "\n",
        "# Set batch size and initialize DataLoader\n",
        "batch_size = 64\n",
        "test_loader = DataLoader(dataset=SAE_test_activations, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Clear cache at the start and set model to evaluation mode\n",
        "sae.clear_cache()\n",
        "sae.eval()\n",
        "\n",
        "# Iterate over test data\n",
        "with torch.no_grad():\n",
        "    for activations in test_loader:\n",
        "        # Get outputs and cache activations for this batch\n",
        "        outputs = sae(activations, cache_activations=True)\n",
        "        \n",
        "        # Process activations from fc1 for the batch\n",
        "        fc1_activations = sae.get_cached_activations('encoder')\n",
        "        \n",
        "        # Iterate through the batch to find max activation for each image\n",
        "        for i in range(fc1_activations.size(0)):  # Iterate through batch size\n",
        "            activations = fc1_activations[i]\n",
        "            \n",
        "            # Find the max activation value and corresponding neuron index\n",
        "            max_value, neuron_index = torch.max(activations, 0)\n",
        "            \n",
        "            # Append results to dictionary\n",
        "            results_dict[\"Max_Value\"].append(max_value.item())\n",
        "            results_dict[\"Neuron_Index\"].append(neuron_index.item())\n",
        "        \n",
        "        # Clear cache manually after processing this batch\n",
        "        sae.clear_cache()\n",
        "\n",
        "# Convert the dictionary to a DataFrame\n",
        "SAE_results_df = pd.DataFrame(results_dict)\n",
        "SAE_results_df['Predicted_Label'] = MNIST_results_df['Predicted_Label']\n",
        "\n",
        "# After the loop, the DataFrame will contain max activations and neuron indices\n",
        "SAE_results_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "SAE_results_df.to_csv('docs/SAE_results.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Track for each neuron what parts of the weights it is activating on"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### META-SAE Max Activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Initialize a dictionary to store results\n",
        "results_dict = {\"Max_Value\": [], \"Neuron_Index\": []}\n",
        "\n",
        "# Set batch size and initialize DataLoader\n",
        "batch_size = 64\n",
        "test_loader = DataLoader(dataset=META_SAE_test_activations, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Clear cache at the start and set model to evaluation mode\n",
        "meta_sae.clear_cache()\n",
        "meta_sae.eval()\n",
        "\n",
        "# Iterate over test data\n",
        "with torch.no_grad():\n",
        "    for activations in test_loader:\n",
        "        # Get outputs and cache activations for this batch\n",
        "        outputs = meta_sae(activations, cache_activations=True)\n",
        "        \n",
        "        # Process activations from fc1 for the batch\n",
        "        fc1_activations = meta_sae.get_cached_activations('encoder')\n",
        "        \n",
        "        # Iterate through the batch to find max activation for each image\n",
        "        for i in range(fc1_activations.size(0)):  # Iterate through batch size\n",
        "            activations = fc1_activations[i]\n",
        "            \n",
        "            # Find the max activation value and corresponding neuron index\n",
        "            max_value, neuron_index = torch.max(activations, 0)\n",
        "            \n",
        "            # Append results to dictionary\n",
        "            results_dict[\"Max_Value\"].append(max_value.item())\n",
        "            results_dict[\"Neuron_Index\"].append(neuron_index.item())\n",
        "        \n",
        "        # Clear cache manually after processing this batch\n",
        "        meta_sae.clear_cache()\n",
        "\n",
        "# Convert the dictionary to a DataFrame\n",
        "META_SAE_results_df = pd.DataFrame(results_dict)\n",
        "META_SAE_results_df['Predicted_Label'] = MNIST_results_df['Predicted_Label']\n",
        "\n",
        "# After the loop, the DataFrame will contain max activations and neuron indices\n",
        "META_SAE_results_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "META_SAE_results_df.to_csv('docs/META_SAE_results.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What have I done so far? \n",
        "\n",
        "-- created the max activation validations\n",
        "- fixed some bugs \n",
        "- cached all activations \n",
        "- looked at fc1 & encoders of both after parsing through it \n",
        "\n",
        "Next Steps: \n",
        "- Analyze the max activations + MAKE GRAPHS!!! (DONE) \n",
        "- Look at Vit-Prisma to see how they track the vision transformer over time \n",
        "- Look at [showing-sae-latents-are-not-atomic-using-meta-saes](https://www.alignmentforum.org/posts/TMAmHh4DdMr4nCSr5/showing-sae-latents-are-not-atomic-using-meta-saes) to see how they analyzed meta saes \n",
        "- automated interpretability [Anthropic Auto-Interp Methods](https://arc.net/l/quote/jukxthen)\n",
        "\n",
        "Confusions: \n",
        "- What else can I do besides max activations to track features + latents?\n",
        "- What happens when I do the decoder instead of the encoder? Can I take something out of the decoder or is the activation just the output. \n",
        "- What is an SAE dictionary size\n",
        "\n",
        "Observations: \n",
        "- The meta-sae is super sparse \n",
        "- the sae is also pretty sparse \n",
        "\n",
        "Future Ideas:\n",
        "- Make it deeper (MNIST & saes)\n",
        "- Batch TOpk? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Goal\n",
        "- Look at ViT Prisma Shape stuff cause that one is prediction dependent\n",
        "- Try doing automated interpretability on MNIST \n",
        "- measure contribution of each feature to the output??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "#load in data\n",
        "# pass in 100000 images \n",
        "# for each neuron see what max activates \n",
        "# save those as graphs I guess "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'dotenv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m login\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Load environment variables from the .env file\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dotenv'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Load environment variables from the .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Get the Hugging Face token from the environment variables\n",
        "hf_token = os.getenv('HUGGINGFACE_TOKEN')\n",
        "# Authenticate with Hugging Face\n",
        "if hf_token:\n",
        "    login(hf_token)\n",
        "else:\n",
        "    print(\"HUGGINGFACE_TOKEN is not set in the .env file.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "batch_size = 64\n",
        "# Data augmentation and normalization for training\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(28, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Normalization for validation\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Load CIFAR10 dataset\n",
        "# train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "# val_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_val)\n",
        "\n",
        "# Load CIFAR100 dataset\n",
        "train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
        "val_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_val)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Image Grid Plans \n",
        "\n",
        "- Goal: To see what each neuron maximally activates on in the test set of images --> leads to crude feature understanding \n",
        "\n",
        "Broad Steps:\n",
        "- Pass an image into the mnist [x]\n",
        "- Store all the activations [x]\n",
        "- Pass the activations into the sae [x]\n",
        "- retrive the activations from the encoder [x]\n",
        "- Stack those activations for all images [x]\n",
        "- Then for each neuron find the top 10 activating images\n",
        "- Store those images to a file in a grid \n",
        "\n",
        "Future Steps:\n",
        "- Auto-interp with a VLM "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/bl/kzfk5ts90gj98y9jcv49ynmc0000gn/T/ipykernel_71267/2540337022.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('models/mnist_colored.pth'))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = ColoredMNISTModel()\n",
        "model.load_state_dict(torch.load('models/mnist_colored.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 782/782 [00:15<00:00, 49.44it/s] \n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model.clear_cache()\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(train_loader):\n",
        "        outputs = model(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([50000, 256])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.get_cached_activations('fc1').shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "selected_layer_config = fc1_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "analysis_activations = model.get_cached_activations(selected_layer_config.name)\n",
        "analysis_loader = DataLoader(analysis_activations, batch_size=batch_size, shuffle=False) # do not shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(analysis_activations, 'embeddings/Colored_MNIST_fc1_activations_CIFAR100.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 782/782 [00:00<00:00, 1335.07it/s]\n"
          ]
        }
      ],
      "source": [
        "# pass the activations through the SAE and save the intermediary activations \n",
        "sae.clear_cache()\n",
        "sae.eval()\n",
        "with torch.no_grad():\n",
        "    for activations in tqdm(analysis_loader):\n",
        "        encoded, decoded = sae(activations, cache_activations=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([50000, 2304])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sae_activations = sae.get_cached_activations('encoder')\n",
        "torch.save(sae_activations, 'embeddings/MNIST_fc1_CIFAR100_sae_activations_colored.pth')\n",
        "sae_activations.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# now I have the sae activations for every image for every neuron \n",
        "#need to validate that the loaders have the same ordering for image "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/bl/kzfk5ts90gj98y9jcv49ynmc0000gn/T/ipykernel_71267/3816802598.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  sae_activations = torch.load('embeddings/MNIST_fc1_CIFAR100_sae_activations_colored.pth')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([50000, 2304])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sae_activations = torch.load('embeddings/MNIST_fc1_CIFAR100_sae_activations_colored.pth')\n",
        "sae_activations.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "transposed = sae_activations.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2304, 50000])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transposed.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_10_indices_per_neuron = torch.argsort(transposed, descending=True, dim=1)[:, :10]\n",
        "max_10_indices_per_neuron_value = torch.gather(transposed, 1, max_10_indices_per_neuron)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2304, 10])\n"
          ]
        }
      ],
      "source": [
        "print(max_10_indices_per_neuron_value.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.6215, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.9464, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.8668, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.2532, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.5026, 0.3303, 0.0296, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(3)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([2.0143, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.3152, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.4235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0204, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0755, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0060, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0319, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([3.0354, 1.4894, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0708, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0329, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([22.2231, 22.0376, 21.9084, 21.3665, 21.2399, 21.1752, 21.1588, 21.0257,\n",
            "        20.9446, 20.9172]) tensor(10)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0081, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0526, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([2.3097, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.8192, 0.3248, 0.0913, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(3)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.5466, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([2.7176, 2.5240, 0.4225, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(3)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([2.4546, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0.1621, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0.5612, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0580, 0.0453, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([2.6095, 0.5588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.4620, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([6.6663, 6.5358, 6.1232, 6.0299, 3.6189, 3.1761, 2.9693, 2.0420, 1.7958,\n",
            "        1.2147]) tensor(10)\n",
            "tensor([0.5435, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.5985, 0.5533, 0.0984, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(3)\n",
            "tensor([0.9058, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0135, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0839, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.6631, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.6777, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.9295, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.0741, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0826, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0203, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([2.0802, 1.5384, 1.3918, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(3)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0112, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.7012, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.9448, 0.7554, 0.2983, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(3)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.8395, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0.0262, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.5872, 0.1157, 0.0177, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(3)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0200, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.1512, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([2.6621, 0.3488, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0.8110, 0.2722, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([2.1001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0677, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0.3738, 0.0821, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0153, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.2563, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0896, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.3047, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([8.5662, 1.6110, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0359, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.5505, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.1726, 0.2195, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.1752, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.9369, 0.8680, 0.3334, 0.3176, 0.1945, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(5)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.8189, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([5.8323, 1.8606, 0.0508, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(3)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.1582, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.9324, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0113, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0.3234, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0798, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.5933, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.9896, 1.6996, 0.0104, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(3)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0675, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([2.5807, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([5.6243, 0.0625, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.4207, 0.6365, 0.5890, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(3)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0374, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0181, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0096, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.4076, 0.0571, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.4927, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0461, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0768, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.0884, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.1700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.3659, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0.0993, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.3016, 0.2159, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.8941, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([2.5676, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.6485, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([3.1480, 1.0429, 0.6918, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(3)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0795, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.3062, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.1012, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.4060, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0917, 0.0877, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.8786, 0.7784, 0.0106, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(3)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0478, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0284, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.8900, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.9314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0149, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.3307, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.2575, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.1446, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.5509, 1.3654, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.1865, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.6791, 0.3483, 0.0164, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(3)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.2851, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.7933, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([2.1535, 0.3401, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0.0193, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.2821, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([2.7714, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.7718, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.3081, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.1290, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0973, 0.0673, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.1722, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([2.3535, 1.3786, 0.9707, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(3)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.8698, 0.4676, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0740, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.1191, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([5.3302, 3.0098, 1.1231, 0.7570, 0.3297, 0.3102, 0.2562, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(7)\n",
            "tensor([0.6980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.5187, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0673, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0355, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.4216, 0.0793, 0.0059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(3)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.0460, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([2.6362, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0356, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([2.0762, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0369, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0075, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0037, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.5844, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([4.6449, 0.2101, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.1701, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.5038, 0.4829, 0.1084, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(3)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.1141, 0.1380, 0.0012, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(3)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.1305, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0429, 0.0249, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.8582, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([5.9783, 4.3264, 0.1495, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(3)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.7225, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.4122, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.1776, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.4073, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([7.4299e+00, 6.0465e+00, 5.3672e+00, 1.6793e+00, 1.4708e+00, 1.1558e+00,\n",
            "        6.6579e-01, 5.3079e-01, 6.0534e-03, 0.0000e+00]) tensor(9)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0987, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([3.4787, 0.4448, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0385, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.9746, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0866, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0.0481, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.1337, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.8637, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.1647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.3468, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0.3748, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([2.3208, 0.0814, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.8176, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.1641, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.5561, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0.3608, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0225, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.3069, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.1192, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.2730, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.4687, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.2339, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.6629, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0.1458, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.5065, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.7171, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0228, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([2.3326, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([1.5284, 0.1225, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.1694, 0.0176, 0.0145, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(3)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.3910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0712, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0253, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.6562, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0318, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.7026, 0.4826, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0.5313, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.6914, 0.2496, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.5540, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.1753, 1.0835, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.2134, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.1082, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.3841, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.5251, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([1.7557, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.8119, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.2453, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.1063, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0075, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.8622, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([2.0089, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([11.0239, 10.0414,  9.9493,  9.6718,  9.5536,  9.4146,  9.4044,  9.3258,\n",
            "         9.3021,  9.2970]) tensor(10)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.5612, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.4919, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([2.0437, 0.0740, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0623, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([3.8079, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.6701, 0.7350, 0.4494, 0.3300, 0.2152, 0.0149, 0.0116, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(7)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.0748, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.7140, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0815, 0.0690, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0291, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([2.8778, 0.5227, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.7826, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([2.3690, 0.3430, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.8423, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.9108, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0.1990, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([6.5134, 0.5087, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0990, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0.4223, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0809, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0.0359, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.9682, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.9736, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0017, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([3.7563, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.6984, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.5015, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.4535, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.3673, 0.2383, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.1843, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.2645, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0742, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.0569, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.7014, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.1369, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0.0074, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0.0334, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.6015, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0054, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.4200, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.8854, 0.9640, 0.6520, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(3)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.1054, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.3048, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.9369, 0.1104, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([2.1986, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.0313, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0006, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([1.0891, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([1.9844, 0.1713, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0372, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([1.3229, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.1407, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0407, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.4157, 0.2352, 0.0640, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(3)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([2.1812, 1.3098, 1.3048, 0.1916, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(4)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0279, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([2.1519, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.9998, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0.1485, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(1)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0.5926, 0.0171, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "        0.0000]) tensor(2)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor(0)\n",
            "tensor(10)\n"
          ]
        }
      ],
      "source": [
        "max = 0\n",
        "max_indices = []\n",
        "for i in range(max_10_indices_per_neuron_value.shape[0]):\n",
        "    values = max_10_indices_per_neuron_value[i]\n",
        "    nonzero_count = torch.count_nonzero(values)\n",
        "\n",
        "    if nonzero_count > max:\n",
        "        max = nonzero_count\n",
        "        max_indices = max_10_indices_per_neuron[i]\n",
        "\n",
        "    print(values, nonzero_count)\n",
        "\n",
        "print(max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.6215, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        ...,\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_10_indices_per_neuron_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2304, 10])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_10_indices_per_neuron.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_10_indices_per_neuron[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.utils import make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Tensor of indices\n",
        "indices = max_10_indices_per_neuron[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "original_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x1000 with 10 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(15, 10))\n",
        "for i in range(10):\n",
        "    idx = indices[i]\n",
        "    img = original_dataset.data[idx]\n",
        "    \n",
        "    plt.subplot(4, 5, i+1)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(f'Index: {idx}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "skipped idx tensor(0)\n",
            "skipped idx tensor(1)\n",
            "skipped idx tensor(2)\n",
            "skipped idx tensor(3)\n",
            "skipped idx tensor(4)\n",
            "skipped idx tensor(5)\n",
            "skipped idx tensor(6)\n",
            "skipped idx tensor(7)\n",
            "skipped idx tensor(8)\n",
            "skipped idx tensor(9)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1500x400 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "indices = max_10_indices_per_neuron[10]\n",
        "\n",
        "plt.figure(figsize=(15, 4))  # Adjusted figure size for 10 images\n",
        "for i, idx in enumerate(indices):\n",
        "    if transposed[0][idx] == 0:\n",
        "        print('skipped idx', idx)\n",
        "        continue\n",
        "\n",
        "    img = train_dataset.data[idx]\n",
        "    \n",
        "    plt.subplot(2, 5, i+1)  # 2 rows, 5 columns\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(f'Index: {idx}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_indices(indices):\n",
        "    plt.figure(figsize=(15, 4))  # Adjusted figure size for 10 images\n",
        "    \n",
        "    for i, idx in enumerate(indices):\n",
        "        img = train_dataset.data[idx]\n",
        "        \n",
        "        plt.subplot(2, 5, i+1)  # 2 rows, 5 columns\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title(f'Index: {idx}')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(len(max_10_indices_per_neuron)):\n",
        "    indices = max_10_indices_per_neuron[i]\n",
        "    plot_indices(indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Saving images to a file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_indices_save(indices, filename, neuron_idx):\n",
        "    plt.figure(figsize=(15, 4))  # Adjusted figure size for 10 images\n",
        "    count = 0\n",
        "    for i, idx in enumerate(indices):\n",
        "        if transposed[neuron_idx][idx] == 0:\n",
        "            print('skipped idx', idx)\n",
        "            continue\n",
        "        count += 1\n",
        "\n",
        "        img = train_dataset.data[idx]\n",
        "        \n",
        "        plt.subplot(2, 5, i+1)  # 2 rows, 5 columns\n",
        "        plt.imshow(img)\n",
        "        plt.axis('off')\n",
        "        plt.title(f'Index: {idx}')\n",
        "\n",
        "    if plt.gca().has_data():\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'docs/neuron_CIFAR100/{count}_{filename}')  # Save the figure to a file\n",
        "    plt.close()  # Close the figure to free memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "all_plots_filename = 'docs/all_neuron_plots.png'\n",
        "plt.figure(figsize=(15, 4 * len(max_10_indices_per_neuron)))  # Adjust height based on number of neurons\n",
        "\n",
        "for i in tqdm(range(len(max_10_indices_per_neuron)), desc=\"Plotting neurons\"):\n",
        "    indices = max_10_indices_per_neuron[i]\n",
        "    plt.subplot(len(max_10_indices_per_neuron), 1, i + 1)  # One row per neuron\n",
        "    plot_indices_save(indices, f'neuron_{i}_plots.png', i)  # Save individual plots if needed\n",
        "\n",
        "plt.savefig(all_plots_filename)  # Save the combined figure\n",
        "plt.close()  # Close the figure to free memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SAE Train Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_sae(train_activations, selected_layer_config=fc1_config, epochs=30):\n",
        "    # Use the selected layer configuration\n",
        "    input_dim = selected_layer_config.input_dim\n",
        "    hidden_dim = 2304\n",
        "    sae = EnhancedSAE(input_dim=input_dim, hidden_dim=hidden_dim, l1_coeff=0.01)\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer_sae = optim.Adam(sae.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Split the activations into train and test sets (80% train, 20% test)\n",
        "    train_activations, test_activations = train_test_split(train_activations, test_size=0.2, random_state=42)\n",
        "\n",
        "    # DataLoader for activations\n",
        "    train_activations_loader = DataLoader(train_activations, batch_size=batch_size, shuffle=True)\n",
        "    test_activations_loader = DataLoader(test_activations, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    SAE_test_activations = test_activations #* Test dataset for SAE class\n",
        "\n",
        "    # Training Loop for SAE\n",
        "    for epoch in range(epochs):\n",
        "        sae.train()\n",
        "        total_loss = 0\n",
        "        for batch in train_activations_loader:\n",
        "            optimizer_sae.zero_grad()  # Zero out previous gradients\n",
        "\n",
        "            # Forward pass through the SAE\n",
        "            encoded, decoded = sae(batch)\n",
        "\n",
        "            # Compute loss (MSE + sparsity penalty)\n",
        "            loss = sae.compute_loss(batch, decoded, encoded)\n",
        "\n",
        "            loss.backward()  # Backprop for SAE\n",
        "            optimizer_sae.step()  # Optimizer step\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"SAE Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_activations_loader):.4f}\")\n",
        "    \n",
        "    sae.eval()\n",
        "    total_test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in test_activations_loader:\n",
        "            # Forward pass through the SAE\n",
        "            encoded, decoded = sae(batch)\n",
        "\n",
        "            # Compute loss (MSE + sparsity penalty)\n",
        "            loss = sae.compute_loss(batch, decoded, encoded)\n",
        "\n",
        "            total_test_loss += loss.item()\n",
        "\n",
        "    print(f\"SAE Test Loss: {total_test_loss/len(test_activations_loader):.4f}\")\n",
        "\n",
        "    return sae, test_activations_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10000, 256])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "colored_model_acts = model.get_cached_activations(fc1_config.name)\n",
        "colored_model_acts.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation Loop for SAE\n",
        "def cache_sae_acts(sae, test_activations_loader):\n",
        "    sae.clear_cache()\n",
        "    sae.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in test_activations_loader:\n",
        "            # Forward pass through the SAE\n",
        "            encoded, decoded = sae(batch, cache_activations=True)\n",
        "    \n",
        "    return sae.get_cached_activations('encoder')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'cache_sae_acts' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sae_activations \u001b[38;5;241m=\u001b[39m \u001b[43mcache_sae_acts\u001b[49m(sae, test_activations_loader)\n\u001b[1;32m      2\u001b[0m sae_activations\u001b[38;5;241m.\u001b[39mshape\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cache_sae_acts' is not defined"
          ]
        }
      ],
      "source": [
        "sae, test_activations_loader = train_sae(colored_model_acts)\n",
        "sae_activations = cache_sae_acts(sae, test_activations_loader)\n",
        "sae_activations.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SAE Epoch [1/30], Loss: 0.0537\n",
            "SAE Epoch [2/30], Loss: 0.0002\n",
            "SAE Epoch [3/30], Loss: 0.0002\n",
            "SAE Epoch [4/30], Loss: 0.0002\n",
            "SAE Epoch [5/30], Loss: 0.0002\n",
            "SAE Epoch [6/30], Loss: 0.0002\n",
            "SAE Epoch [7/30], Loss: 0.0002\n",
            "SAE Epoch [8/30], Loss: 0.0002\n",
            "SAE Epoch [9/30], Loss: 0.0002\n",
            "SAE Epoch [10/30], Loss: 0.0002\n",
            "SAE Epoch [11/30], Loss: 0.0002\n",
            "SAE Epoch [12/30], Loss: 0.0002\n",
            "SAE Epoch [13/30], Loss: 0.0002\n",
            "SAE Epoch [14/30], Loss: 0.0002\n",
            "SAE Epoch [15/30], Loss: 0.0002\n",
            "SAE Epoch [16/30], Loss: 0.0002\n",
            "SAE Epoch [17/30], Loss: 0.0002\n",
            "SAE Epoch [18/30], Loss: 0.0002\n",
            "SAE Epoch [19/30], Loss: 0.0001\n",
            "SAE Epoch [20/30], Loss: 0.0001\n",
            "SAE Epoch [21/30], Loss: 0.0001\n",
            "SAE Epoch [22/30], Loss: 0.0001\n",
            "SAE Epoch [23/30], Loss: 0.0001\n",
            "SAE Epoch [24/30], Loss: 0.0001\n",
            "SAE Epoch [25/30], Loss: 0.0001\n",
            "SAE Epoch [26/30], Loss: 0.0001\n",
            "SAE Epoch [27/30], Loss: 0.0001\n",
            "SAE Epoch [28/30], Loss: 0.0001\n",
            "SAE Epoch [29/30], Loss: 0.0001\n",
            "SAE Epoch [30/30], Loss: 0.0001\n",
            "SAE Test Loss: 0.0002\n"
          ]
        }
      ],
      "source": [
        "meta_sae, _ = train_sae(sae_activations, selected_layer_config=encoder_config, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(meta_sae.state_dict(), 'models/mnist_meta_sae_colored.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
