{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "path = '/Volumes/Sid_Drive/mnist/'\n",
    "\n",
    "if os.path.exists(path):\n",
    "    prefix = path\n",
    "else:\n",
    "    prefix = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/Sid_Drive/mnist/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm \n",
    "\n",
    "class CrossDatasetAnalyzer:\n",
    "    def __init__(self, dataset_names, max_depth=9, prefix=prefix):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            prefix: Path prefix for loading files\n",
    "            dataset_names: List of dataset names to analyze\n",
    "            max_depth: Maximum depth to analyze\n",
    "        \"\"\"\n",
    "        self.prefix = prefix\n",
    "        self.dataset_names = dataset_names\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    def load_depth_embeddings(self, depth, dataset_name):\n",
    "        \"\"\"Load embeddings for a specific depth and dataset\"\"\"\n",
    "        path = f'{self.prefix}embeddings/mnist_encoder_{dataset_name}_depth_{depth}.pth'\n",
    "        return torch.load(path)\n",
    "    \n",
    "    def analyze_activation_patterns(self, activations):\n",
    "        \"\"\"Analyze activation patterns\"\"\"\n",
    "        metrics = {}\n",
    "        \n",
    "        # 1. Activation Statistics\n",
    "        metrics['mean_activation'] = torch.mean(activations).item()\n",
    "        metrics['activation_std'] = torch.std(activations).item()\n",
    "        metrics['sparsity'] = (activations == 0).float().mean().item()\n",
    "        \n",
    "        # 2. Active Feature Count\n",
    "        threshold = activations.mean() + activations.std()\n",
    "        active_features = (activations > threshold).sum(dim=1)\n",
    "        metrics['avg_active_features'] = active_features.float().mean().item()\n",
    "        \n",
    "        # 3. Feature Utilization\n",
    "        feature_usage = (activations > threshold).float().mean(dim=0)\n",
    "        metrics['feature_utilization'] = feature_usage.mean().item()\n",
    "        metrics['feature_utilization_std'] = feature_usage.std().item()\n",
    "        \n",
    "        # 4. Activation Distribution\n",
    "        normalized = torch.nn.functional.softmax(activations, dim=1)\n",
    "        activation_entropy = entropy(normalized.numpy(), axis=1)\n",
    "        metrics['activation_entropy'] = np.mean(activation_entropy)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def compare_datasets(self):\n",
    "        \"\"\"Compare activation patterns across datasets and depths\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for dataset_name in tqdm(self.dataset_names, desc=\"Processing datasets\"):\n",
    "            depth_metrics = []\n",
    "            \n",
    "            for depth in tqdm(range(1, self.max_depth + 1), desc=f\"Processing depth for {dataset_name}\"):\n",
    "                try:\n",
    "                    # Load embeddings for this depth\n",
    "                    activations = self.load_depth_embeddings(depth, dataset_name)\n",
    "                    \n",
    "                    # Analyze patterns\n",
    "                    metrics = self.analyze_activation_patterns(activations)\n",
    "                    depth_metrics.append(metrics)\n",
    "                    \n",
    "                except FileNotFoundError:\n",
    "                    print(f\"No embeddings found for {dataset_name} at depth {depth}\")\n",
    "                    break\n",
    "                \n",
    "            results[dataset_name] = depth_metrics\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def plot_metrics_across_depths(self, results):\n",
    "        \"\"\"Plot how metrics change across depths for each dataset\"\"\"\n",
    "        metrics = list(next(iter(results.values()))[0].keys())\n",
    "        \n",
    "        for metric in metrics:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            for dataset_name in self.dataset_names:\n",
    "                values = [m[metric] for m in results[dataset_name]]\n",
    "                plt.plot(range(1, len(values) + 1), values, label=dataset_name)\n",
    "            \n",
    "            plt.xlabel('Depth')\n",
    "            plt.ylabel(metric)\n",
    "            plt.title(f'{metric} vs Depth')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(f\"plots/hypothesis/mnist_{metric}.png\")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = CrossDatasetAnalyzer(['MNIST', 'CIFAR100', 'EMNIST_letter', 'EMNIST'], max_depth=9, prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing datasets:   0%|          | 0/1 [00:00<?, ?it/s]/var/folders/bl/kzfk5ts90gj98y9jcv49ynmc0000gn/T/ipykernel_15149/4241552981.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(path)\n",
      "Processing depth for EMNIST_letter:   0%|          | 0/9 [00:00<?, ?it/s]\n",
      "Processing datasets: 100%|██████████| 1/1 [00:00<00:00, 155.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No embeddings found for EMNIST_letter at depth 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = analyzer.compare_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43manalyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_metrics_across_depths\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 78\u001b[0m, in \u001b[0;36mCrossDatasetAnalyzer.plot_metrics_across_depths\u001b[0;34m(self, results)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_metrics_across_depths\u001b[39m(\u001b[38;5;28mself\u001b[39m, results):\n\u001b[1;32m     77\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Plot how metrics change across depths for each dataset\"\"\"\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m metrics:\n\u001b[1;32m     81\u001b[0m         plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "analyzer.plot_metrics_across_depths(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
