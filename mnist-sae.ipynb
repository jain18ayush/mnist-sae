{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x10835eed0>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MNISTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNISTModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)  # Input layer (28x28 pixels)\n",
        "        self.fc2 = nn.Linear(128, 64)       # Hidden layer\n",
        "        self.fc3 = nn.Linear(64, 10)        # Output layer (10 classes)\n",
        "\n",
        "        # Initialize a cache to store lists of activations\n",
        "        self.activation_cache = {\n",
        "            'fc1': [],\n",
        "            'fc2': [],\n",
        "            'fc3': []\n",
        "        }\n",
        "\n",
        "    def forward(self, x, cache_activations=False):\n",
        "        x = x.view(-1, 28 * 28)  # Flatten the input image\n",
        "        \n",
        "        # Pass through fc1 and cache activations if needed\n",
        "        fc1_out = torch.relu(self.fc1(x))\n",
        "        if cache_activations:\n",
        "            self.activation_cache['fc1'].append(fc1_out.detach().clone())  # Append fc1 activations\n",
        "        \n",
        "        # Pass through fc2 and cache activations if needed\n",
        "        fc2_out = torch.relu(self.fc2(fc1_out))\n",
        "        if cache_activations:\n",
        "            self.activation_cache['fc2'].append(fc2_out.detach().clone())  # Append fc2 activations\n",
        "        \n",
        "        # Pass through fc3 and cache activations if needed\n",
        "        fc3_out = self.fc3(fc2_out)\n",
        "        if cache_activations:\n",
        "            self.activation_cache['fc3'].append(fc3_out.detach().clone())  # Append fc3 activations\n",
        "\n",
        "        return fc3_out\n",
        "\n",
        "    # Method to retrieve cached activations for a specified layer\n",
        "    def get_cached_activations(self, layer_name):\n",
        "        return torch.cat(self.activation_cache[layer_name]) if layer_name in self.activation_cache else None\n",
        "\n",
        "    # Method to clear the cache\n",
        "    def clear_cache(self):\n",
        "        self.activation_cache = {\n",
        "            'fc1': [],\n",
        "            'fc2': [],\n",
        "            'fc3': []\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IkB3CSGham1e",
        "outputId": "eeb79734-1272-4180-e8f2-a56ec1ccb09a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Loss: 0.2645\n",
            "Epoch [2/5], Loss: 0.1110\n",
            "Epoch [3/5], Loss: 0.0776\n",
            "Epoch [4/5], Loss: 0.0612\n",
            "Epoch [5/5], Loss: 0.0484\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "epochs = 5\n",
        "\n",
        "# MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))  # Mean and std deviation of MNIST dataset\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "MNIST_test_dataset = test_dataset #* Test dataset for mnist class \n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Initialize model, loss function and optimizer\n",
        "model = MNISTModel()\n",
        "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "all_activations = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()  # Zero out previous gradients\n",
        "        outputs = model(images)  # Get output and activations from fc2\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Gradient descent\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Store activations for the sparse autoencoder\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 97.58%\n"
          ]
        }
      ],
      "source": [
        "#* Test Accuracy Loop \n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"Test accuracy: {100 * correct / total}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cache Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "#* Test Accuracy Loop \n",
        "model.clear_cache()\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images, cache_activations=True)\n",
        "        _, predicted = torch.max(outputs.data, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([10000, 128]), torch.Size([10000, 64]), torch.Size([10000, 10]))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.get_cached_activations('fc1').shape, model.get_cached_activations('fc2').shape, model.get_cached_activations('fc3').shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10000])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_loader.dataset.targets.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL6Kne88HFOj"
      },
      "source": [
        "## SAE\n",
        "\n",
        "*Activations Shapes:* \n",
        "- fc1: torch.Size([10000, 128])\n",
        "- fc2: torch.Size([10000, 64])\n",
        "- fc3: torch.Size([10000, 10]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LayerConfig:\n",
        "    def __init__(self, name, input_dim):\n",
        "        self.name = name\n",
        "        self.input_dim = input_dim\n",
        "\n",
        "# Create instances for each layer\n",
        "fc1_config = LayerConfig('fc1', 128)\n",
        "fc2_config = LayerConfig('fc2', 64)\n",
        "fc3_config = LayerConfig('fc3', 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Simple SAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrVJaAeOhmi6",
        "outputId": "94f61f99-4fbe-480c-b659-2264b4f70426"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class SimpleSAE(nn.Module):\n",
        "    def __init__(self, input_dim=64, hidden_dim=32, l1_coeff=0.1, seed=42):\n",
        "        super(SimpleSAE, self).__init__()\n",
        "        torch.manual_seed(seed)\n",
        "        self.encoder = nn.Linear(input_dim, hidden_dim)\n",
        "        self.decoder = nn.Linear(hidden_dim, input_dim)\n",
        "        self.l1_coeff = l1_coeff  # L1 regularization coefficient for sparsity\n",
        "        \n",
        "        # Initialize a cache to store lists of activations\n",
        "        self.activation_cache = {\n",
        "            'encoder': [],\n",
        "            'decoder': []\n",
        "        }\n",
        "\n",
        "    def forward(self, x, cache_activations=False):\n",
        "        # Encoder: Reduce the dimensionality\n",
        "        encoded = torch.relu(self.encoder(x))\n",
        "        if cache_activations:\n",
        "            self.activation_cache['encoder'].append(encoded.detach().clone())  # Append encoder activations\n",
        "\n",
        "        # Decoder: Reconstruct the original input\n",
        "        decoded = self.decoder(encoded)\n",
        "        if cache_activations:\n",
        "            self.activation_cache['decoder'].append(decoded.detach().clone())  # Append decoder activations\n",
        "\n",
        "        return encoded, decoded\n",
        "\n",
        "    def compute_loss(self, x, decoded, encoded):\n",
        "        # Reconstruction Loss (MSE)\n",
        "        recon_loss = nn.MSELoss()(decoded, x)\n",
        "\n",
        "        # L1 Sparsity Loss (L1 regularization on encoded activations)\n",
        "        l1_loss = self.l1_coeff * torch.sum(torch.abs(encoded))\n",
        "\n",
        "        # Combine losses: L = MSE + λ * L1\n",
        "        loss = recon_loss + l1_loss\n",
        "\n",
        "        return loss\n",
        "\n",
        "    # Method to retrieve cached activations for a specified layer\n",
        "    def get_cached_activations(self, layer_name):\n",
        "        return torch.cat(self.activation_cache[layer_name]) if layer_name in self.activation_cache else None\n",
        "\n",
        "    # Method to clear the cache\n",
        "    def clear_cache(self):\n",
        "        self.activation_cache = {\n",
        "            'encoder': [],\n",
        "            'decoder': []\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math \n",
        "import torch.nn.functional as F\n",
        "\n",
        "class EnhancedSAE(nn.Module):\n",
        "    def __init__(self, input_dim=64, hidden_dim=32, l1_coeff=0.1, seed=42):\n",
        "        super(EnhancedSAE, self).__init__()\n",
        "        self.l1_coeff = l1_coeff  # L1 regularization coefficient for sparsity\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "        # Encoder and decoder with Kaiming initialization\n",
        "        self.encoder = nn.Linear(input_dim, hidden_dim)\n",
        "        self.decoder = nn.Linear(hidden_dim, input_dim)\n",
        "\n",
        "        nn.init.kaiming_uniform_(self.encoder.weight, a=math.sqrt(5))\n",
        "        nn.init.kaiming_uniform_(self.decoder.weight, a=math.sqrt(5))\n",
        "        self.encoder.bias.data.zero_()\n",
        "        self.decoder.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Center the input\n",
        "        x_centered = x - self.decoder.bias\n",
        "        # Encoder: Reduce the dimensionality\n",
        "        encoded = F.relu(self.encoder(x_centered))\n",
        "        # Decoder: Reconstruct the original input\n",
        "        decoded = self.decoder(encoded)\n",
        "\n",
        "        return encoded, decoded\n",
        "\n",
        "    def compute_loss(self, x, decoded, encoded):\n",
        "        # Reconstruction Loss (MSE)\n",
        "        recon_loss = nn.MSELoss()(decoded, x)\n",
        "\n",
        "        # L1 Sparsity Loss (L1 regularization on encoded activations)\n",
        "        l1_loss = self.l1_coeff * torch.sum(torch.abs(encoded))\n",
        "\n",
        "        # Combine losses: L = MSE + λ * L1\n",
        "        loss = recon_loss + l1_loss\n",
        "\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SAE Epoch [1/5], Loss: 15.6593\n",
            "SAE Epoch [2/5], Loss: 8.7535\n",
            "SAE Epoch [3/5], Loss: 8.4562\n",
            "SAE Epoch [4/5], Loss: 8.1989\n",
            "SAE Epoch [5/5], Loss: 7.9738\n"
          ]
        }
      ],
      "source": [
        "# Choose the layer configuration you want to use\n",
        "selected_layer_config = fc1_config  # Change this to fc2_config or fc3_config as needed\n",
        "\n",
        "# Use the selected layer configuration\n",
        "input_dim = selected_layer_config.input_dim\n",
        "hidden_dim = 32\n",
        "sae = SimpleSAE(input_dim=input_dim, hidden_dim=hidden_dim, l1_coeff=0.1)\n",
        "\n",
        "# Optimizer\n",
        "optimizer_sae = optim.Adam(sae.parameters(), lr=learning_rate)\n",
        "\n",
        "# Activations loaded from cache\n",
        "train_activations = model.get_cached_activations(selected_layer_config.name)\n",
        "\n",
        "# Split the activations into train and test sets (80% train, 20% test)\n",
        "train_activations, test_activations = train_test_split(train_activations, test_size=0.2, random_state=42)\n",
        "\n",
        "# DataLoader for activations\n",
        "train_activations_loader = DataLoader(train_activations, batch_size=batch_size, shuffle=True)\n",
        "test_activations_loader = DataLoader(test_activations, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "SAE_test_activations = test_activations #* Test dataset for SAE class\n",
        "\n",
        "# Training Loop for SAE\n",
        "epochs = 5  # You can adjust this based on your preference\n",
        "for epoch in range(epochs):\n",
        "    sae.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_activations_loader:\n",
        "        optimizer_sae.zero_grad()  # Zero out previous gradients\n",
        "\n",
        "        # Forward pass through the SAE\n",
        "        encoded, decoded = sae(batch)\n",
        "\n",
        "        # Compute loss (MSE + sparsity penalty)\n",
        "        loss = sae.compute_loss(batch, decoded, encoded)\n",
        "\n",
        "        loss.backward()  # Backprop for SAE\n",
        "        optimizer_sae.step()  # Optimizer step\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"SAE Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_activations_loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SAE Test Loss: 7.9110\n"
          ]
        }
      ],
      "source": [
        "# Evaluation Loop for SAE\n",
        "sae.eval()\n",
        "total_test_loss = 0\n",
        "with torch.no_grad():\n",
        "    for batch in test_activations_loader:\n",
        "        # Forward pass through the SAE\n",
        "        encoded, decoded = sae(batch)\n",
        "\n",
        "        # Compute loss (MSE + sparsity penalty)\n",
        "        loss = sae.compute_loss(batch, decoded, encoded)\n",
        "\n",
        "        total_test_loss += loss.item()\n",
        "\n",
        "print(f\"SAE Test Loss: {total_test_loss/len(test_activations_loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What have I done so far? \n",
        "\n",
        "- Created MNIST: ~97% accuracy \n",
        "- Trained two SAEs on MNIST\n",
        "    - SimpleSAE (just encoder decoder)\n",
        "    - ComplexSae (Based off of Neel Nanda's sae when replicating monosemanticity paper) \n",
        "- Simple seems to performs slightly better \n",
        "\n",
        "*Set to a random seed* \n",
        " \n",
        "Next Steps: \n",
        "- Cache all activations when testing the sae\n",
        "- Take the middle layer of the encoder of sae and pass it back into simple sae \n",
        "\n",
        "Confusions: \n",
        "- Should the hidden layer of an SAE be larger than the input\n",
        "    - *What is a hidden layer?* \n",
        "\n",
        "### NEED TO TRACK MAX ACTIVATIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Meta-SAE Time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoder_config = LayerConfig('encoder', 32)\n",
        "decoder_config = LayerConfig('decoder', 128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cache activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation Loop for SAE\n",
        "sae.clear_cache()\n",
        "sae.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in test_activations_loader:\n",
        "        # Forward pass through the SAE\n",
        "        encoded, decoded = sae(batch, cache_activations=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([2000, 32]), torch.Size([2000, 128]))"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get cached activations\n",
        "sae.get_cached_activations('encoder').shape, sae.get_cached_activations('decoder').shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "selected_layer_config = encoder_config\n",
        "input_dim = selected_layer_config.input_dim\n",
        "hidden_dim = 16\n",
        "meta_sae = SimpleSAE(input_dim=input_dim, hidden_dim=hidden_dim, l1_coeff=0.1)\n",
        "\n",
        "optimizer_sae = optim.Adam(meta_sae.parameters(), lr=learning_rate)\n",
        "\n",
        "train_activations = sae.get_cached_activations(selected_layer_config.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SAE Epoch [1/5], Loss: 4.4836\n",
            "SAE Epoch [2/5], Loss: 3.2285\n",
            "SAE Epoch [3/5], Loss: 2.1484\n",
            "SAE Epoch [4/5], Loss: 1.2984\n",
            "SAE Epoch [5/5], Loss: 0.5460\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_activations, test_activations = train_test_split(train_activations, test_size=0.2, random_state=42)\n",
        "\n",
        "META_SAE_test_activations = test_activations #* Test dataset for META_SAE class\n",
        "\n",
        "train_activations_loader = DataLoader(train_activations, batch_size=batch_size, shuffle=True)\n",
        "test_activations_loader = DataLoader(test_activations, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    meta_sae.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_activations_loader:\n",
        "        optimizer_sae.zero_grad()\n",
        "        encoded, decoded = meta_sae(batch)\n",
        "\n",
        "        loss = meta_sae.compute_loss(batch, decoded, encoded)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer_sae.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"SAE Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_activations_loader):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Notes\n",
        "\n",
        "- meta sae has reallly good loss???\n",
        "- Whats topk and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation\n",
        "\n",
        "How does ViT Prisma do thier emjoi thing? --> Want to track the change in the models understanding of the number over time. \n",
        "wth is a logit --> \n",
        "\n",
        "- Max Activation Evalution\n",
        "\n",
        "1.  MNIST: Run the train set and cache activations \n",
        "        *Store the output labels*\n",
        "2.  Take the labels from the MNIST test and run those activations through the SAE and track max activations of the encoder output layer. \n",
        "3.  Take the acrtivations of the encoder output and track max activations of the encoder output layer \n",
        "\n",
        "(2) (3) can have a function in the simple sae class to help with tracking max activations of the SAE \n",
        "\n",
        "\n",
        "- model -> MNIST \n",
        "- sae -> MNIST Sae \n",
        "- meta-sae -> Sae on MNIST Sae\n",
        "\n",
        "\n",
        "Need to rename all the data loaders to be by class\n",
        "\n",
        "### What data do I have + want?\n",
        "- labels from MNIST\n",
        "- activations of the encoder for each sae\n",
        "- activations of fc1, 2, 3 for mnist \n",
        "\n",
        "- for each activation what is the max neuron and its value --> what was the expected number "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MNIST Max Activations\n",
        "\n",
        "1. Save the top neuron that activated and its value. \n",
        "2. Run the test set through and save the labels. \n",
        "3. After the run and having the cache iterate through the cache and labels \n",
        "4. Add to a df the argmax ( neuron) and max value \n",
        "5. add the projected label as well \n",
        "\n",
        "*Critical Oversight: The model will change its prediction over time and I am not tracking that* "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MNIST_test_dataset #*dataset run through MNIST \n",
        "print(SAE_test_activations) #* MNIST activations run through sae\n",
        "print(META_SAE_test_activations) #* Sae activations run through meta-sae    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "#* Generates the Cache ??????? --> but fc1 is the activation cache and we have the labels from testloader\n",
        "batch_size = 64\n",
        "\n",
        "test_loader = DataLoader(dataset=MNIST_test_dataset, batch_size=batch_size, shuffle=False)\n",
        "model.clear_cache()\n",
        "model.eval()\n",
        "predicted_set = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images, cache_activations=True)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        predicted_set.append(predicted)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10000, 128])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fc1_activations = model.get_cached_activations('fc1')\n",
        "fc1_activations.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Max_Value</th>\n",
              "      <th>Neuron_Index</th>\n",
              "      <th>Predicted_Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.392313</td>\n",
              "      <td>46</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.096921</td>\n",
              "      <td>63</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.499483</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12.808185</td>\n",
              "      <td>92</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10.635261</td>\n",
              "      <td>74</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Max_Value  Neuron_Index  Predicted_Label\n",
              "0   8.392313            46                7\n",
              "1  13.096921            63                2\n",
              "2   7.499483            29                1\n",
              "3  12.808185            92                0\n",
              "4  10.635261            74                4"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Initialize a dictionary to store results\n",
        "results_dict = {\"Max_Value\": [], \"Neuron_Index\": [], \"Predicted_Label\": []}\n",
        "\n",
        "# Set batch size and initialize DataLoader\n",
        "batch_size = 64\n",
        "test_loader = DataLoader(dataset=MNIST_test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Clear cache at the start and set model to evaluation mode\n",
        "model.clear_cache()\n",
        "model.eval()\n",
        "\n",
        "# Iterate over test data\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        # Get outputs and cache activations for this batch\n",
        "        outputs = model(images, cache_activations=True)\n",
        "        \n",
        "        # Predicted labels for the batch\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        \n",
        "        # Process activations from fc1 for the batch\n",
        "        fc1_activations = model.get_cached_activations('fc1')\n",
        "        \n",
        "        # Iterate through the batch to find max activation for each image\n",
        "        for i in range(fc1_activations.size(0)):  # Iterate through batch size\n",
        "            activations = fc1_activations[i]\n",
        "            \n",
        "            # Find the max activation value and corresponding neuron index\n",
        "            max_value, neuron_index = torch.max(activations, 0)\n",
        "            \n",
        "            # Append results to dictionary\n",
        "            results_dict[\"Max_Value\"].append(max_value.item())\n",
        "            results_dict[\"Neuron_Index\"].append(neuron_index.item())\n",
        "            results_dict[\"Predicted_Label\"].append(predicted[i].item())\n",
        "        \n",
        "        # Clear cache manually after processing this batch\n",
        "        model.clear_cache()\n",
        "\n",
        "# Convert the dictionary to a DataFrame\n",
        "MNIST_results_df = pd.DataFrame(results_dict)\n",
        "\n",
        "# After the loop, the DataFrame will contain max activations and neuron indices\n",
        "MNIST_results_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
