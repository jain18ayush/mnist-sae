{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x13059aed0>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MNISTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNISTModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)  # Input layer (28x28 pixels)\n",
        "        self.fc2 = nn.Linear(128, 64)       # Hidden layer\n",
        "        self.fc3 = nn.Linear(64, 10)        # Output layer (10 classes)\n",
        "\n",
        "        # Initialize a cache to store lists of activations\n",
        "        self.activation_cache = {\n",
        "            'fc1': [],\n",
        "            'fc2': [],\n",
        "            'fc3': []\n",
        "        }\n",
        "\n",
        "    def forward(self, x, cache_activations=False):\n",
        "        x = x.view(-1, 28 * 28)  # Flatten the input image\n",
        "        \n",
        "        # Pass through fc1 and cache activations if needed\n",
        "        fc1_out = torch.relu(self.fc1(x))\n",
        "        if cache_activations:\n",
        "            self.activation_cache['fc1'].append(fc1_out.detach().clone())  # Append fc1 activations\n",
        "        \n",
        "        # Pass through fc2 and cache activations if needed\n",
        "        fc2_out = torch.relu(self.fc2(fc1_out))\n",
        "        if cache_activations:\n",
        "            self.activation_cache['fc2'].append(fc2_out.detach().clone())  # Append fc2 activations\n",
        "        \n",
        "        # Pass through fc3 and cache activations if needed\n",
        "        fc3_out = self.fc3(fc2_out)\n",
        "        if cache_activations:\n",
        "            self.activation_cache['fc3'].append(fc3_out.detach().clone())  # Append fc3 activations\n",
        "\n",
        "        return fc3_out\n",
        "\n",
        "    # Method to retrieve cached activations for a specified layer\n",
        "    def get_cached_activations(self, layer_name):\n",
        "        return torch.cat(self.activation_cache[layer_name]) if layer_name in self.activation_cache else None\n",
        "\n",
        "    # Method to clear the cache\n",
        "    def clear_cache(self):\n",
        "        self.activation_cache = {\n",
        "            'fc1': [],\n",
        "            'fc2': [],\n",
        "            'fc3': []\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IkB3CSGham1e",
        "outputId": "eeb79734-1272-4180-e8f2-a56ec1ccb09a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Loss: 0.2645\n",
            "Epoch [2/5], Loss: 0.1110\n",
            "Epoch [3/5], Loss: 0.0776\n",
            "Epoch [4/5], Loss: 0.0612\n",
            "Epoch [5/5], Loss: 0.0484\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "epochs = 5\n",
        "\n",
        "# MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))  # Mean and std deviation of MNIST dataset\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Initialize model, loss function and optimizer\n",
        "model = MNISTModel()\n",
        "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "all_activations = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()  # Zero out previous gradients\n",
        "        outputs = model(images)  # Get output and activations from fc2\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Gradient descent\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Store activations for the sparse autoencoder\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 97.58%\n"
          ]
        }
      ],
      "source": [
        "#* Test Accuracy Loop \n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"Test accuracy: {100 * correct / total}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Cache Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "#* Test Accuracy Loop \n",
        "model.clear_cache()\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images, cache_activations=True)\n",
        "        _, predicted = torch.max(outputs.data, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([10000, 128]), torch.Size([10000, 64]), torch.Size([10000, 10]))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.get_cached_activations('fc1').shape, model.get_cached_activations('fc2').shape, model.get_cached_activations('fc3').shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10000])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_loader.dataset.targets.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL6Kne88HFOj"
      },
      "source": [
        "## SAE\n",
        "\n",
        "*Activations Shapes:* \n",
        "- fc1: torch.Size([10000, 128])\n",
        "- fc2: torch.Size([10000, 64])\n",
        "- fc3: torch.Size([10000, 10]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LayerConfig:\n",
        "    def __init__(self, name, input_dim):\n",
        "        self.name = name\n",
        "        self.input_dim = input_dim\n",
        "\n",
        "# Create instances for each layer\n",
        "fc1_config = LayerConfig('fc1', 128)\n",
        "fc2_config = LayerConfig('fc2', 64)\n",
        "fc3_config = LayerConfig('fc3', 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Simple SAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrVJaAeOhmi6",
        "outputId": "94f61f99-4fbe-480c-b659-2264b4f70426"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class SimpleSAE(nn.Module):\n",
        "    def __init__(self, input_dim=64, hidden_dim=32, l1_coeff=0.1, seed=42):\n",
        "        super(SimpleSAE, self).__init__()\n",
        "        torch.manual_seed(seed)\n",
        "        self.encoder = nn.Linear(input_dim, hidden_dim)\n",
        "        self.decoder = nn.Linear(hidden_dim, input_dim)\n",
        "        self.l1_coeff = l1_coeff  # L1 regularization coefficient for sparsity\n",
        "        \n",
        "        # Initialize a cache to store lists of activations\n",
        "        self.activation_cache = {\n",
        "            'encoder': [],\n",
        "            'decoder': []\n",
        "        }\n",
        "\n",
        "    def forward(self, x, cache_activations=False):\n",
        "        # Encoder: Reduce the dimensionality\n",
        "        encoded = torch.relu(self.encoder(x))\n",
        "        if cache_activations:\n",
        "            self.activation_cache['encoder'].append(encoded.detach().clone())  # Append encoder activations\n",
        "\n",
        "        # Decoder: Reconstruct the original input\n",
        "        decoded = self.decoder(encoded)\n",
        "        if cache_activations:\n",
        "            self.activation_cache['decoder'].append(decoded.detach().clone())  # Append decoder activations\n",
        "\n",
        "        return encoded, decoded\n",
        "\n",
        "    def compute_loss(self, x, decoded, encoded):\n",
        "        # Reconstruction Loss (MSE)\n",
        "        recon_loss = nn.MSELoss()(decoded, x)\n",
        "\n",
        "        # L1 Sparsity Loss (L1 regularization on encoded activations)\n",
        "        l1_loss = self.l1_coeff * torch.sum(torch.abs(encoded))\n",
        "\n",
        "        # Combine losses: L = MSE + λ * L1\n",
        "        loss = recon_loss + l1_loss\n",
        "\n",
        "        return loss\n",
        "\n",
        "    # Method to retrieve cached activations for a specified layer\n",
        "    def get_cached_activations(self, layer_name):\n",
        "        return torch.cat(self.activation_cache[layer_name]) if layer_name in self.activation_cache else None\n",
        "\n",
        "    # Method to clear the cache\n",
        "    def clear_cache(self):\n",
        "        self.activation_cache = {\n",
        "            'encoder': [],\n",
        "            'decoder': []\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math \n",
        "import torch.nn.functional as F\n",
        "\n",
        "class EnhancedSAE(nn.Module):\n",
        "    def __init__(self, input_dim=64, hidden_dim=32, l1_coeff=0.1, seed=42):\n",
        "        super(EnhancedSAE, self).__init__()\n",
        "        self.l1_coeff = l1_coeff  # L1 regularization coefficient for sparsity\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "        # Encoder and decoder with Kaiming initialization\n",
        "        self.encoder = nn.Linear(input_dim, hidden_dim)\n",
        "        self.decoder = nn.Linear(hidden_dim, input_dim)\n",
        "\n",
        "        nn.init.kaiming_uniform_(self.encoder.weight, a=math.sqrt(5))\n",
        "        nn.init.kaiming_uniform_(self.decoder.weight, a=math.sqrt(5))\n",
        "        self.encoder.bias.data.zero_()\n",
        "        self.decoder.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Center the input\n",
        "        x_centered = x - self.decoder.bias\n",
        "        # Encoder: Reduce the dimensionality\n",
        "        encoded = F.relu(self.encoder(x_centered))\n",
        "        # Decoder: Reconstruct the original input\n",
        "        decoded = self.decoder(encoded)\n",
        "\n",
        "        return encoded, decoded\n",
        "\n",
        "    def compute_loss(self, x, decoded, encoded):\n",
        "        # Reconstruction Loss (MSE)\n",
        "        recon_loss = nn.MSELoss()(decoded, x)\n",
        "\n",
        "        # L1 Sparsity Loss (L1 regularization on encoded activations)\n",
        "        l1_loss = self.l1_coeff * torch.sum(torch.abs(encoded))\n",
        "\n",
        "        # Combine losses: L = MSE + λ * L1\n",
        "        loss = recon_loss + l1_loss\n",
        "\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SAE Epoch [1/5], Loss: 15.6593\n",
            "SAE Epoch [2/5], Loss: 8.7535\n",
            "SAE Epoch [3/5], Loss: 8.4562\n",
            "SAE Epoch [4/5], Loss: 8.1989\n",
            "SAE Epoch [5/5], Loss: 7.9738\n"
          ]
        }
      ],
      "source": [
        "# Choose the layer configuration you want to use\n",
        "selected_layer_config = fc1_config  # Change this to fc2_config or fc3_config as needed\n",
        "\n",
        "# Use the selected layer configuration\n",
        "input_dim = selected_layer_config.input_dim\n",
        "hidden_dim = 32\n",
        "sae = SimpleSAE(input_dim=input_dim, hidden_dim=hidden_dim, l1_coeff=0.1)\n",
        "\n",
        "# Optimizer\n",
        "optimizer_sae = optim.Adam(sae.parameters(), lr=learning_rate)\n",
        "\n",
        "# Activations loaded from cache\n",
        "train_activations = model.get_cached_activations(selected_layer_config.name)\n",
        "\n",
        "# Split the activations into train and test sets (80% train, 20% test)\n",
        "train_activations, test_activations = train_test_split(train_activations, test_size=0.2, random_state=42)\n",
        "\n",
        "# DataLoader for activations\n",
        "train_activations_loader = DataLoader(train_activations, batch_size=batch_size, shuffle=True)\n",
        "test_activations_loader = DataLoader(test_activations, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Training Loop for SAE\n",
        "epochs = 5  # You can adjust this based on your preference\n",
        "for epoch in range(epochs):\n",
        "    sae.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_activations_loader:\n",
        "        optimizer_sae.zero_grad()  # Zero out previous gradients\n",
        "\n",
        "        # Forward pass through the SAE\n",
        "        encoded, decoded = sae(batch)\n",
        "\n",
        "        # Compute loss (MSE + sparsity penalty)\n",
        "        loss = sae.compute_loss(batch, decoded, encoded)\n",
        "\n",
        "        loss.backward()  # Backprop for SAE\n",
        "        optimizer_sae.step()  # Optimizer step\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"SAE Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_activations_loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SAE Test Loss: 7.9110\n"
          ]
        }
      ],
      "source": [
        "# Evaluation Loop for SAE\n",
        "sae.eval()\n",
        "total_test_loss = 0\n",
        "with torch.no_grad():\n",
        "    for batch in test_activations_loader:\n",
        "        # Forward pass through the SAE\n",
        "        encoded, decoded = sae(batch)\n",
        "\n",
        "        # Compute loss (MSE + sparsity penalty)\n",
        "        loss = sae.compute_loss(batch, decoded, encoded)\n",
        "\n",
        "        total_test_loss += loss.item()\n",
        "\n",
        "print(f\"SAE Test Loss: {total_test_loss/len(test_activations_loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What have I done so far? \n",
        "\n",
        "- Created MNIST: ~97% accuracy \n",
        "- Trained two SAEs on MNIST\n",
        "    - SimpleSAE (just encoder decoder)\n",
        "    - ComplexSae (Based off of Neel Nanda's sae when replicating monosemanticity paper) \n",
        "- Simple seems to performs slightly better \n",
        "\n",
        "*Set to a random seed* \n",
        " \n",
        "Next Steps: \n",
        "- Cache all activations when testing the sae\n",
        "- Take the middle layer of the encoder of sae and pass it back into simple sae \n",
        "\n",
        "Confusions: \n",
        "- Should the hidden layer of an SAE be larger than the input\n",
        "    - *What is a hidden layer?* \n",
        "\n",
        "### NEED TO TRACK MAX ACTIVATIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Meta-SAE Time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoder_config = LayerConfig('encoder', 32)\n",
        "decoder_config = LayerConfig('decoder', 128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cache activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation Loop for SAE\n",
        "sae.clear_cache()\n",
        "sae.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in test_activations_loader:\n",
        "        # Forward pass through the SAE\n",
        "        encoded, decoded = sae(batch, cache_activations=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([2000, 32]), torch.Size([2000, 128]))"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get cached activations\n",
        "sae.get_cached_activations('encoder').shape, sae.get_cached_activations('decoder').shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "selected_layer_config = encoder_config\n",
        "input_dim = selected_layer_config.input_dim\n",
        "hidden_dim = 16\n",
        "meta_sae = SimpleSAE(input_dim=input_dim, hidden_dim=hidden_dim, l1_coeff=0.1)\n",
        "\n",
        "optimizer_sae = optim.Adam(meta_sae.parameters(), lr=learning_rate)\n",
        "\n",
        "train_activations = sae.get_cached_activations(selected_layer_config.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SAE Epoch [1/5], Loss: 4.4836\n",
            "SAE Epoch [2/5], Loss: 3.2285\n",
            "SAE Epoch [3/5], Loss: 2.1484\n",
            "SAE Epoch [4/5], Loss: 1.2984\n",
            "SAE Epoch [5/5], Loss: 0.5460\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_activations, test_activations = train_test_split(train_activations, test_size=0.2, random_state=42)\n",
        "\n",
        "train_activations_loader = DataLoader(train_activations, batch_size=batch_size, shuffle=True)\n",
        "test_activations_loader = DataLoader(test_activations, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    meta_sae.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_activations_loader:\n",
        "        optimizer_sae.zero_grad()\n",
        "        encoded, decoded = meta_sae(batch)\n",
        "\n",
        "        loss = meta_sae.compute_loss(batch, decoded, encoded)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer_sae.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"SAE Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_activations_loader):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Notes\n",
        "\n",
        "- meta sae has reallly good loss???\n",
        "- Whats topk and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluation\n",
        "\n",
        "How does ViT Prisma do thier emjoi thing? --> Want to track the change in the models understanding of the number over time. \n",
        "\n",
        "- Max Activation Evalution\n",
        "\n",
        "(1) MNIST: Run the train set and cache activations \n",
        "--- Store the output labels \n",
        "(2) Take the labels from the MNIST test and run those activations through the SAE and track max activations of the encoder output layer. \n",
        "(3) Take the acrtivations of the encoder output and track max activations of the encoder output layer \n",
        "\n",
        "(2) (3) can have a function in teh simple sae class to help with tracking max activations of the SAE "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MNIST Max Activations\n",
        "\n",
        "Save the top "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
